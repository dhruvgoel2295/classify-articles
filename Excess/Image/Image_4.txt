Image and Vision Computing 30 (2012) 474–475

Contents lists available at SciVerse ScienceDirect

Image and Vision Computing
journal homepage: www.elsevier.com/locate/imavis

The road to intelligence☆
Maria Petrou ⁎
Informatics and Telematics Institute CERTH, Greece
Imperial College London, United Kingdom

a r t i c l e
Keywords:
Intelligent systems
System architecture
Tower of knowledge
Human language

i n f o

a b s t r a c t
It is argued that robotic platforms are the way forward towards building intelligent systems, where multiple
sensors and manipulation are used for cognitive processes. It is also argued that the cue for developing the
right architecture for such a system is human language.
© 2012 Elsevier B.V. Open access under CC BY-NC-ND license.

For several years now we have been trying to make intelligent
vision systems. To facilitate the process, we have also postulated the
use of prior knowledge which we incorporate in the top down
approaches. To acquire that knowledge we have used the sledge hammer of statistics, with, sometimes, hundreds of examples and counter
examples. Alternatively, we have simply inserted it in the form of
rules or constraints. And yet, despite all our successes, we have not
developed a really intelligent vision system yet! I believe the reason
is simple: we have ignored the process.
When image processing appeared in the horizon of scientiﬁc disciplines, people tried to solve the problem of edge detection by developing
ever more sophisticated edge detection ﬁlters. Nobody in his right mind
tries to do that now: it has become understood for some time that edge
detection is only part of a process, the vision process, where what used to
be termed low, intermediate and high level vision work together and inseparably. One might like to call that “the small uniﬁcation principle”.
What I would like to express here is “the grand uniﬁcation principle”
of artiﬁcial cognition: cognition does not rely on a single sense, neither
on static information. We acquire knowledge from our interaction with
the outside world. This is not only via our vision, but via all our senses
and with the help of manipulating objects: we hold, feel, touch, smell,
turn them round, and even taste them! Were the pioneers of image processing and vision silly to consider edge detection as an isolated task?
Certainly not! They were simply following the strategy “divide and conquer”. The big problem had to be tackled from somewhere, and isolating
a subpart of it was an excellent idea. Are people who use only vision to
build intelligent systems silly? Certainly not! We have been dividing
and conquering all the time. But, we have reached now the end of the
road for this approach. Now, we have to move to the next level up,
where vision is only an inseparable part of a much bigger, much more
complex process. And we have reached the end of the road from many
☆ This paper has been recommended for acceptance by special issue Opinions Editor
Sinisa Todorovic.
⁎ Tel.: + 44 483 571281.
E-mail address: maria.petrou@imperial.ac.uk.
0262-8856 © 2012 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.imavis.2011.10.005

directions, all of them leading to the same end: platforms! Robotics!
Now, we need to put all our clever systems together and start treating
them as integral subparts of a much more complex architecture. Will
the incorporation of smell complicate things? Perhaps, to begin with,
but it will help solve many problems. How else can you distinguish a
beautifully made plastic banana from a real one? Will the incorporation
of dynamic information help recognition? Yes! How else can you distinguish a ﬂoor-touching window from a door, if you do not have the
patience to wait until you see somebody going in and out through
there? Trying to perform recognition with hundreds of cameras ﬁxed
on the ceiling of a lab is a brute force approach. Nature works more
frugally: it gave us only two cameras, two hands to manipulate the
object, and two legs to move around objects if they are too big for manipulation. It also gave us memory to make mental notes for the uses of
objects we observe around us: “Aha, I saw somebody drinking from
that thing. It must be a glass and not a vase”.
However, if we want to develop such a complex super-system, we
have to decide upon its basic structure ﬁrst. We need to form a skeleton,
where we shall start adding components, all compatible with each
other, all interacting, all capable of complementing each other. To
work out such a framework we need to look at the structure of the
system we wish to imitate: understanding how the human brain
works is still work in progress, with a long way to go yet. We have, however, a highly organised output of human intelligence: human language.
Actually, it is not clear whether intelligence came ﬁrst and language
followed, or language developed ﬁrst and intelligence followed. I
believe here that we have another grant uniﬁcation process in practice:
they must have both developed together and hand in hand. One may
think of a society as an entity of its own right, with its subsystems and
subparts being the humans that make it up. So, if the subparts do not
communicate to work together, one cannot have an intelligent society.
In short, I consider language and intelligence totally intertwined. I consider means of communication and intelligence inseparable and made
to serve each other. I believe, therefore, that language is the gateway
to the structure of intelligence. Over the millennia people have studied
systematically the language structure and developed elaborate

M. Petrou / Image and Vision Computing 30 (2012) 474–475

grammars and syntactic rules to express it. The basic ingredients are the
words that come in ten categories, according to the foundations of
grammar established by ancient Greeks: articles, nouns, adjectives,
pronouns, verbs, participles, prepositions, adverbs, conjunctions and
interjections. These types of word are designed to be used in answering
the questions: “what is it?”, nouns; “what is it doing?”, verbs; “how is
it?”, adjectives; “how is it doing it?”, adverbs and participles; and
“where is it?”, prepositions. We may ignore for the time being the
articles, conjunctions and interjections, which may be treated as auxiliary types of word for higher order reﬁnements. Classical pattern recognition attempts to answer the question “what is it?”. Thus it works with
nouns only. More recently, research in action recognition tries to answer the question “what is he doing?”. Thus it tries to recognise verbs.
Classical feature extraction methods try to answer the question “how
is it?”. Thus they work with adjectives, which are often called features,
which may be used in the process of recognition. Vision concerned
with object detection tries to answer the question “where?”, thus dealing with prepositions, while questions like “how is he doing it?” are related with research in recognising actions, like distinguishing running
from walking. It has become evident also in recent years that answers
to the question “how is he doing it?” can help identify a person (gait recognition, behavioural biometrics). So, we have a convergence, where
actions are used for recognising objects. I would go one step further: actions can be used to recognise objects which participate in them from
the function they perform: something is a spoon because somebody
eats soup with it. Adjectives should express the features an object
should have in order to be able to participate in these actions. Thus, a
spoon is not something white or silver-like which is next to a plate,
but something that somebody used to eat a liquid. The contextual information that helps recognise the spoon is not that it sits next to a soup
dish (I could leave my screw-driver or my packet of cigarettes next to
my plate) but the fact that spoon and soup dish participated in the
same action.
In view of the above, I have proposed the Tower of Knowledge
(Fig. 1) as a multilayer architecture that allows the incorporation of
static as well as dynamic information, multiple sensors and sensor
interrogation for adjective conﬁrmation, as the means of recognising
objects and building around it an artiﬁcial intelligence platform [1,2].
In conclusion, I believe that building intelligent systems requires
the incorporation of manipulation as well as the use of all types of

475

Fig. 1. The Tower of Knowledge consists of separate networks for pixels/image regions,
labels (nouns), actions (verbs) and features (adjectives). The networks exchange
information between themselves, while speciﬁc characteristics may be conﬁrmed or
rejected by interrogating the battery of available sensors. Classical pattern recognition,
which solves the labelling problem, operates solely in the level of nouns, irrespective of
whether it uses hierarchical labelling schemes or not.

sensor available; that the communication protocol between system
sub-modules is an inseparable part of the system's intelligence;
therefore language is the gateway to human intelligence, and as a
consequence it can serve as the major cue in the structure and organisation of artiﬁcial intelligence architectures.
References
[1] M. Petrou, Learning in Computer Vision: Some Thoughts, LNCS 4756, Springer,
2007, pp. 1–12.
[2] M. Xu, M. Petrou, 3D scene interpretation by combining probability theory and
logic: the Tower of Knowledge, CVIU 115 (11) (2011) 1581–1596.

