Neural Networks 71 (2015) 37–44

Contents lists available at ScienceDirect

Neural Networks
journal homepage: www.elsevier.com/locate/neunet

Stability and synchronization of memristor-based fractional-order
delayed neural networks
Liping Chen a , Ranchao Wu b , Jinde Cao c,d,∗ , Jia-Bao Liu b
a

School of Electrical Engineering and Automation, Hefei University of Technology, Hefei 230009, China

b

School of Mathematics, Anhui University, Hefei 230039, China

c

Department of Mathematics, Southeast University, Nanjing 210096, China

d

Department of Mathematics, Faculty of Science, King Abdulaziz University, Jeddah 21589, Saudi Arabia

article

info

Article history:
Received 24 December 2014
Received in revised form 3 July 2015
Accepted 23 July 2015
Available online 31 July 2015
Keywords:
Fractional-order
Memristor-based neural networks
Stability
Synchronization

abstract
Global asymptotic stability and synchronization of a class of fractional-order memristor-based delayed
neural networks are investigated. For such problems in integer-order systems, Lyapunov–Krasovskii
functional is usually constructed, whereas similar method has not been well developed for fractionalorder nonlinear delayed systems. By employing a comparison theorem for a class of fractional-order linear
systems with time delay, sufficient condition for global asymptotic stability of fractional memristor-based
delayed neural networks is derived. Then, based on linear error feedback control, the synchronization
criterion for such neural networks is also presented. Numerical simulations are given to demonstrate the
effectiveness of the theoretical results.
© 2015 Elsevier Ltd. All rights reserved.

1. Introduction
In 1971, circuit theorist Prof. L.O. Chua originally envisioned
the existence of a fourth fundamental circuit element called memristor (Chua, 1971). Almost four decades later, the first memristor device was experimentally confirmed by the researchers of
Hewlett–Packard (HP) who reported on Nature in 2008 (Strukov,
Snider, Stewart, & Williams, 2008). Memristor is a nonlinear resistor with memory, whose the most interesting feature is that it can
memorize electric charge flowed in what direction through it in
the past. It is with such characteristic which makes it possible to
process and storage information with low power. In recent years,
it have been showed that memristor devices have many promising applications in pattern recognition, programmable logic,
signal processing, reconfigurable computing, brain–computer interfaces, control system and so on (see Driscoll, Quinn, & Klein,
2010; Shin, Kim, & Kang, 2011; Yan, Choe, Nam, Hu, Das, Klemic,
Ellenbogen, & Lieber, 2011; Yang, Strukov, & Stewart, 2013).
Particularly necessary to point out, in order to simulate the artificial neural network of human brain better, in large-scale nonlinear analog circuit of neural network, the self feedback connection
weights and connection weights implemented by the traditional

∗ Corresponding author at: Department of Mathematics, Southeast University,
Nanjing 210096, China.
E-mail address: jdcao@seu.edu.cn (J. Cao).
http://dx.doi.org/10.1016/j.neunet.2015.07.012
0893-6080/© 2015 Elsevier Ltd. All rights reserved.

resistors have been replaced by memristors to form a new model
of neural networks, which is known as memristor-based neural
networks (MNN) (Thomas, 2013). Now, dynamics analysis and
applications of MNN have been attracted increasing attention, (see Adhikari, Yang, Kim, & Chua, 2012; Ebong & Mazumder,
2012; Wang & Shen, 2014; Wen, Bao, Zeng, Chen, & Huang, 2013;
Wu & Zeng, 2012; Zhang, Shen, & Sun, 2012; Zhang, Shen, Yin,
& Sun, 2013) and references therein. In particular, in view of the
potential applications in diverse areas such as secure communication (Zhou, Chen, & Xiang, 2005), information science (Bondarenko, 2005), biological system (Molinari, Leggio, & Thaut, 2007),
pattern recognition (Haken, 2006) and so on, synchronization
of neural networks has gained considerable attention in recent
years (Rakkiyappan, Chandrasekar, Park, & Kwon, 2014), which
also include MNN for the special feature of memristor. Some positive and interesting results on synchronization of MNN have been
obtained, see (Chandrasekar, Rakkiyappan, Cao, & Lakshmanand,
2014; Guo, Wang, & Yan, 2015; Jiang, Wang, Mei, & Shen, 2015;
Li & Cao, 2015; Wang & Shen, 2015; Wen, Zeng, Huang, & Chen,
2013b; Wu, Wen, & Zeng, 2012; Zhang & Shen, 2014).
Fractional calculus is a branch of mathematical analysis, which
mainly deals with derivatives and integrals of arbitrary noninteger order. Although it has a long mathematical history, the
applications of fractional calculus to physics and engineering
are only a recent focus of interest (Caponetto, 2010; Podlubny,
1999; Saptarshi & Indranil, 2012; Valerio, 2012). Since fractional

38

L. Chen et al. / Neural Networks 71 (2015) 37–44

derivatives are nonlocal and have weakly singular kernels, compared with integer-order calculus, the major advantage is that
they provide an excellent instrument for the description of memory and hereditary properties of various materials and processes.
In order to better describe the dynamical behavior of the neurons, such as ‘‘infinite-memory’’, some researchers recently introduced it to neural networks to form fractional-order neural
networks (FNN) (Anastasio, 1994; Anastassiou, 2012; Lundstrom,
Higgs, Spain, & Fairhall, 2008). Previous studies have confirmed
that the incorporation of memory terms (a fractional derivative
or integral operator) into neural network models is an important improvement (Kaslika & Sivasundaram, 2012). The main advantage of fractional-order neural networks in comparison with
integer-order model lies in two aspects, one is its infinite memory, the other is that fractional-order parameter enriches the
system performance by increasing one degree of freedom. Very
recently, many researchers have focused on FNN, some important
and interesting results on dynamics behaviors and synchronization
of FNN have been achieved in this new field (Chen, Chai, Wu, Ma,
& Zhai, 2013; Chen, Qu, Chai, Wu, & Qi, 2013; Huang, Zhao, Wang,
& Li, 2012; Song & Cao, 2014; Stamova, 2014; Wang, Yu, & Wen,
2014; Yu, Hu, Jiang, & Fan, 2014), which was also carried out on
memristor-based fractional-order neural networks (MFNN), for instance, global Mittag-Leffler stability and synchronization of MFNN
were investigated in Ref. (Chen, Zeng, & Jiang, 2014). Sufficient conditions for projective synchronization of MFNN have been obtained
in Ref. (Bao & Cao, 2015). The problem of the existence, uniqueness and uniform stability of MFNN with two different types of
memductance functions was extensively investigated in Ref.
(Rakkiyappan, Velmurugan, & Cao, 2015). Finite-time stability
of fractional-order complex-valued memristor-based neural networks with time delays was discussed in Ref. (Rakkiyappan et al.,
2014).
Note that the existing results (Bao & Cao, 2015; Chen et al.,
2014; Rakkiyappan et al., 2014) for stability and synchronization
of MFNN are independent of delay. In fact, in circuit implementation of neural networks, due to the finite switching speeds of
the amplifiers, time delays are inevitable, it will affect the stability of a network by creating instability, oscillation and chaos
phenomena. Hence, it is of foremost importance to discuss the
stability of delayed MFNN. Ref. (Rakkiyappan et al., 2015) considered stability of fractional-order complex-valued memristor-based
neural networks with time delays, but it focuses on finite-time
stability from the non-Lyapunov point of view. On the other hand,
in recent years, some results about asymptotic stability and synchronization of integer-order MNN are constantly emerging, which
are all dependent on the Lyapunov–Krasovskii stability theory for
functional differential equations and the linear matrix inequality
(LMI) approach. However, similar tools have not been developed
for fractional-order nonlinear delayed systems. These approaches
could not be extended to fractional-order MNN easily and that is
why there are few works about FMNN. Thus, to find out new ways
to cope with the problems is very challenging. To the best of our
knowledge, there are few results on the global asymptotic stability
and synchronization of delayed MFNN.
Motivated by the above discussions, in this paper, by using
comparison theorem and stability theorem for fractional-order
linear delayed system, a method for analysis on stability of delayed
MFNN is established. On the basis of this, sufficient conditions for
global asymptotic stability and synchronization of delayed MFNN
are presented. The main contribution of this paper can be described
in brief as follows: (1) to investigate stability and synchronization
of delayed MFNN by employing a comparison theorem for
fractional-order linear systems with time delay; (2) our results is
on globally asymptotic stability of FMNN with delay for the first
time; (3) compared with the earlier results in the literature, the
obtained results are more general and less conservative.

The rest of the paper is organized as follows. Some necessary
definitions, lemmas and the delayed MFNN are given in Section 2.
Two sufficient conditions ensuring the global asymptotic stability
and synchronization of delayed MFNN in Section 3 are presented.
Three numerical examples are provided in Section 4.
2. Preliminaries and model description
From the Laplace transform of fractional derivative, it is
recognized that the main advantage of the Caputo derivative is that
it only requires initial conditions given in terms of integer-order
derivatives, representing well-understood features of physical
situations and making it more applicable to real world problems.
So in the rest of the paper, we deal with the fractional-order neural
networks involving Caputo derivative.
Definition 1 (Podlubny, 1999). The fractional integral with noninteger order α > 0 of function x(t ) is defined as follows:
D−α
t0 ,t x(t ) =

1

Γ (q)

t



(t − τ )α−1 x(τ )dτ ,

t0

where Γ (·) is the Gamma function, Γ (s) =

∞
0

t s−1 e−t dt.

Definition 2 (Podlubny, 1999). The Caputo derivative of fractional
order α of function x(t ) is defined as follows:
α

C Dt0 ,t x

n−α)
(t ) = Dt−(
0 ,t

dn
dt n

1

=

x(t )



Γ (n − α)

t

(t − τ )n−α−1 x(n) (τ )dτ ,

t0

where n − 1 < α < n ∈ Z + .
In the following, the notation Dα is chosen as the Caputo fractional
derivative operator C Dα0,t .
In the paper, referring to some relevant works on memristorbased fractional-order neural networks (Bao & Cao, 2015; Chen
et al., 2014; Rakkiyappan et al., 2014), a class of memristorbased fractional-order neural networks with delay described by
the following equation are considered.
Dα xi (t ) = −ci xi (t ) +

n


aij (xi (t ))fj (xj (t ))

j =1

+

n


bij (xi (t ))gj (xj (t − τ )) + Ii ,

i ∈ N = {1, 2, . . . , n},

(1)

j =1

where xi (t ) is the state variable of the ith neuron (the voltage of
capacitor), ci > 0 is the self-regulating parameters of the neurons,
aij (xi (t )) and bij (xi (t )) are memristive connective weights, which
denote the neuron interconnection matrix and the delayed neuron
interconnection matrix, respectively. fj , gj : R → R are bounded
feedback functions with and without time-delay between the jthdimension of the memristor and xi (t ). Ii represents the external input. Let C ([−τ , 0], Rn ) be Banach space of all continuous functions,
where time-delay τ > 0. The initial conditions of (1) are given by
x(s) = ϕ(s) = (ϕ1 (s), ϕ2 (s), . . . , ϕn (s))T ∈ C ([−τ , 0], Rn ). For
more detailed information, one can refer to Refs. (Adhikari et al.,
2012; Ebong & Mazumder, 2012; Wang & Shen, 2014; Wen et al.,
2013; Wu & Zeng, 2012; Zhang et al., 2012, 2013). According to the
feature of memristor, denote
aij (xi (t )) =
bij (xi (t )) =



aˆ ij ,
aˇ ij ,

|xj (t )| < Tj ,
|xj (t )| > Tj ,

bˆ ij ,
bˇ ij ,

|xj (t )| < Tj ,
|xj (t )| > Tj ,



L. Chen et al. / Neural Networks 71 (2015) 37–44

aij (±Tj ) = aˆ ij or aˇ ij , bij (±Tj ) = bˆ ij or bˇ ij , where switching jumps
Ti > 0 , aˆ ij , aˇ ij , bˆ ij , bˇ ij are known constants relating to memristances.
It is obvious that system (1) is a discontinuous systems. Its
solution cannot be defined by the classical solution. In order to
obtain the solution of systems (1), solutions of all the systems
considered in the following are intended in Filippov’s sense
(Filippov, 1988). As the literature (Bao & Cao, 2015; Chen et al.,
2014), by applying the theories of set-valued maps and differential
inclusions to system (1), system (1) can be written as the following
differential inclusion,
α

D xi (t ) ∈ −ci xi (t ) +

n


co[aij (xj (t ))]fj (xj (t ))

j =1

+

n


co[bij (xj (t ))]gj (xj (t − τ )) + Ii ,

t > 0, i ∈ N ,

(2)

39

and the linear fractional-order differential systems with time delay
Dα v(t ) = −av(t ) + bv(t − τ ),
v(t ) = ϕ(t ), t ∈ [−τ , 0],

t > 0,



(4)

where u(t ) ∈ R and v(t ) ∈ R are continuous and nonnegative in
[0, +∞), and ϕ(t ) ≥ 0, t ∈ [−τ , 0].
If a > 0 and b > 0, then
u(t ) ≤ v(t ), t ∈ [0, +∞).
Lemma 3 (Deng, Li, & Lu, 2007). For fractional-order linear delayed systems (4), the zero solution of system (4) is Lyapunov globally asymptotically stable, if the following characteristic equation
of (4) has no purely imaginary roots and −a + b < 0,
sα + a − be−sτ = 0.

j =1

or there exist a˜ ij (xi (t )) ∈ co[aij (xj (t ))], b˜ ij (xi (t )) ∈ co[bij (xj (t ))],
for i, j ∈ N, such that
Dα xi (t ) = −ci xi (t ) +

n


Assumption 1. The neuron activation functions fj , gj are bounded,
fj (±Tj ) = gj (±Tj ) = 0, and satisfy the following Lipschitz
condition with Lipschitz constant Fj , Gj > 0,

a˜ ij (xi (t ))fj (xj (t ))

j =1

+

n


b˜ ij (xi (t ))gj (xj (t − τ )) + Ii ,

t > 0, i ∈ N ,

(3)

j=1

where co[u, v] denotes the closure of convex hull generated by real
numbers u and v or real matrices u and v , and


co[aij (xj (t ))] =

aˆ ij , |xj (t )| < Tj ,
co{ˆaij , aˇ ij }, |xj (t )| = Tj ,
aˇ ij , |xj (t )| > Tj ,

co[aij (xj (t ))]fj (x∗j (t ))

j =1

co[bij (xj (t ))]gj (x∗j (t )) + Ii ,

a˜ ij (x∗i (t ))fj (x∗j (t )) +

j =1

n


b˜ ij (x∗i (t ))gj (x∗j (t )) + Ii = 0.

j =1

Lemma 1 (Zhang, Yu, & Wang, 2015). If h(t ) ∈ C 1 ([0, +∞), R)
denotes a continuously differentiable function, for any α ∈ (0, 1),
the following inequality holds almost everywhere:
Dα |h(t )| ≤ sgn(h(t ))Dα h(t ).

α

D u(t ) ≤ −au(t ) + bu(t − τ ),
u(t ) = ϕ(t ), t ∈ [−τ , 0],

 

n
> max Gi
b∗ji > 0,
1≤i≤n

j =1

j =1

Lemma 4 (Chen et al., 2014). Under Assumption 1, if fj (±Tj ) = 0,
gj (±Tj ) = 0(j ∈ N ), then

|co[aij (xj (t ))]xj (t ) − co[aij (yj (t ))]yj (t )| ≤ a∗ij Fj |xj (t ) − yj (t )|,
|co[bij (xj (t ))]xj (t ) − co[bij (yj (t ))]yj (t )| ≤ b∗ij Gj |xj (t ) − yj (t )|,
that is, for any ηij (xj (t )) ∈ co[aij (xj (t ))], ηij (yj (t )) ∈ co[aij (yj (t ))],
γij (xj (t )) ∈ co[bij (xj (t ))], γij (yj (t )) ∈ co[bij (yj (t ))], one has

|ηij (xj (t ))fj (xj (t )) − ηij (yj (t ))fj (yj (t ))| ≤ a∗ij Fj |xj (t ) − yj (t )|,

3. Main results
3.1. Global asymptotic stability
In this section, a sufficient condition for the existence, uniqueness and global asymptotic stability of the equilibrium point of system (1) is presented.
Theorem 3.1. Under Assumptions 1 and 2, system (1) admits a
unique equilibrium point x∗ (t ), which is asymptotically stable.
Proof. Let ci xi = µi and constructing a mapping Θ : Rn → Rn ,
defined by

Lemma 2 (Wang, Yu, Wen, Zhang, & Yu, 2015). Consider the
following fractional-order differential inequality with time delay





where a∗ij = max{|ˆaij |, ∥ˇaij |}, b∗ij = max{|bˆ ij |, ∥bˇ ij |} for i, j ∈ N.

or there exist a˜ ij (x∗i (t )) ∈ co[aij (xj (t ))], b˜ ij (x∗i (t )) ∈ co[bij (xj (t ))],
for i, j ∈ N, such that
n


a∗ji

|γij (xj (t ))gj (xj (t )) − γij (yj (t ))gj (yj (t ))| ≤ b∗ij Gj |xj (t ) − yj (t )|,

j =1

−ci x∗i (t ) +

n


where a∗ji = max{|ˆaji |, ∥ˇaji |}, b∗ji = max{|bˆ ji |, ∥bˇ ji |}.

Definition 3 (Zhang et al., 2012). A constant vector x (t ) =
(x∗1 (t ), x∗2 (t ), . . . , x∗n (t ))T is an equilibrium point of system (1) in
Filippov’s sense, if x∗ (t ) satisfies the differential inclusion

+

Assumption 2. ci , aij , bij , Fj and Gj satisfy the following condition

1≤i≤n

∗

n


|gj (x) − gj (y)| ≤ Gj |x − y|,

for x, y ∈ R and j = 1, 2, . . . , n.



In order to obtain main results, the following definition, assumptions and lemmas are presented firstly.

n


|fj (x) − fj (y)| ≤ Fj |x − y|,

min ci − Fi


 bˆ ij , |xj (t )| < Tj ,
co[bij (xj (t ))] =
co{bˆ , bˇ }, |xj (t )| = Tj ,
 ˇ ij ij
bij , |xj (t )| > Tj .

0 ∈ −ci x∗i (t ) +

To ensure the existence, uniqueness and stability of the equilibrium point of system (1) or fractional differential inclusion (2), the
following assumptions are given.

t > 0,

Φi µi =

n

j=1


aij

µi
ci

 
fj

µi
ci


+

n

j =1


bij

µi
ci




gj

where Φ (µ) = (Φ1 (µ), Φ2 (µ), . . . , Φn (µ))T .

µi
ci



+ Ii ,

40

L. Chen et al. / Neural Networks 71 (2015) 37–44

Now, we will show that Φ is a contraction mapping on Rn
endowed with the Euclidean norm. In fact, for any two different
points u = (u1 , u2 , . . . , un )T , v = (v1 , v2 , . . . , vn )T , we have


 max Gi
1≤i≤n

≤ max

n


b∗ji


+ Fi

j =1

n

j=1

a∗ji 

n


min {ci }

1≤i≤n

i =1

j =1



µ∗i

 

ci

fj

µ∗i


+

ci

n



bij

µ∗i
ci

j =1

n


a˜ ij (x∗i )fj (x∗j (t )) +

j =1

n


|uj − vj |.

Dα v(t ) = −K1 v(t ) + K2 v(t − τ ),
v(t ) = ϕ(t ), t ∈ [−τ , 0],




gj

µ∗i



ci

+ Ii .

b˜ ij (x∗i )gj (x∗j (t )) + Ii ,

j =1

(7)

with the same initial conditions ϕ(t ) in (6).
It follows from Lemma 3 that the zero solution of system
(7) is Lyapunov globally asymptotically stable, if the following
characteristic equation of (7) has no purely imaginary roots and
K1 > K2 ,
(8)

In the following, we prove that characteristic equation (8) has
no pure imaginary roots for any τ > 0 by using contradiction.
Suppose there exists s = ωi = |ω|(cos π2 + i sin π2 ) that is a pure
imaginary root of sα + K1 − K2 e−sτ = 0, where ω is a real number.
If ω > 0, s = ωi = |ω|(cos π2 + i sin( π2 )), and if ω < 0, s = ωi =
|ω|(cos π2 −i sin( π2 )). Substituting s = ωi = |ω|(cos π2 +i sin(± π2 ))
into sα + K1 − K2 e−sτ = 0 gives


 απ 
απ
|ω|α cos
+ i sin ±
+ K1 − K2 (cos ωτ − i sin ωτ ) = 0.
2

2

Separating real and imaginary parts gives

 απ 

 |ω|α cos
+ K1 − K2 cos ωτ = 0,
 2απ 
 |ω|α sin ±
+ K2 sin ωτ = 0,
2

j=1
n

which is equivalent to
co[bij (xj (t ))]gj (xj (t − τ )) − co[bij (x∗i (t ))]gj (x∗ (t ))




|ω|

j=1

or equivalently, there exist
b˜ ⋆ij (yj (t )) ∈ co[bij (xj (t ))]gj (xj (t − τ )) − co[bij (x∗i (t ))]gj (x∗ (t )),
such that
Dα yi (t ) = −ci yi (t ) +

n



a˜ ⋆ij (yj (t )) +

j =1

n



b˜ ⋆ij (yj (t − τ )).

Dα u(t ) = Dα ∥y(t )∥ =

n


(5)

j =1

Constructing auxiliary function u(t ) = ∥y(t )∥ =
It follows from Lemmas 1 and 4 and (5) that

n

i=1

Dα |yi (t )|

n

cos

απ

2



2

+ K1


2
απ
+ sin ±
− K22 = 0,


2

|yi (t )|.

|ω|2α + 2K1 cos

απ
2

|ω|α + K12 − K22 = 0.

(9)

Since |ω|α > 0, cos απ
> 0, K1 > 0, if K1 > K2 , (9) has no
2
real solutions, i.e. characteristic equation (8) has no pure imaginary
roots for any τ > 0, which means that the zero solution of system
(7) is Lyapunov globally asymptotically stable if K1 > K2 . According
to the Lemma 2, ∥y(t )∥ = u(t ) ≤ v(t ), which implies that
∥y(t )∥ is Lyapunov globally asymptotically stable. That is to say,
the equilibrium point x∗ (t ) is asymptotically stable.

n




−ci |yi (t )| +
Fj a∗ji |yj (t )| +
Gj b∗ji |yj (t − τ )|
j =1



3.2. Global synchronization of FMNN

i=1



α

i.e.,

a˜ ⋆ij (yj (t )) ∈ co[aij (xj (t ))]fj (xj (t )) − co[aij (x∗i (t ))]fj (x∗ (t )),

i =1

t > 0,

sα + K1 − K2 e−sτ = 0.



D yi (t ) ∈ − ci xi (t ) − ci x∗i (t )
n



+
co[aij (xj (t ))]fj (xj (t )) − co[aij (x∗i (t ))]fj (x∗ (t ))

≤

|yi (t − τ )|

i =1



α

n

bji

|yi (t )|

i=1

Now, we consider the following fractional-order delayed linear
systems

which implies that x (t ) is an equilibrium point of system (1).
Next, we will prove equilibrium point x∗ (t ) is asymptotically
stable.
One can derive from (3) that the transformation yi (t ) = xi (t ) −
x∗ (t ) transforms system (2) or (3) into the following fractionalorder differential inclusion:



a∗ji


n

j=1



= −K1 u(t ) + K2 u(t − τ ),
(6)


n ∗ 
where K1 = min1≤i≤n ci − Fi j=1 aji > 0, K2 = max1≤i≤n Gi
n ∗ 
j=1 bji > 0.

∗

+

∗

Gj b∗ji |yj (t − τ )|

= −K1 ∥y(t )∥ + K2 ∥y(t − τ )∥

That is, there exist a˜ ij (x∗i ) = aij (x∗i ) ∈ co[aij (xj (t ))], b˜ ij (x∗i ) =
bij (x∗i ) ∈ co[bij (xj (t ))] such that
0 = −ci x∗i (t ) +




n

j =1

1≤i≤n

which implies Φ is a contraction mapping on Rn . Hence, there
exists a unique fixed point µ∗ such that µ∗ = Φ (µ∗ ), i.e.
aij

n 
n


j=1 i=1

n

+ max Gi

∥Φ (u) − Φ (v)∥ < ∥u − v∥,

n




a∗ji |yj (t )| +

j =1

 
n

It follows from (A2) that

µ∗i =

n


1≤i≤n

j =1

1≤i≤n

ci − Fj

≤ − min ci − Fi

cj

j =1

n 




n

∥Φ (u) − Φ (v)∥ =
|Φi (u) − Φi (v)|
i=1

 
   
n 
n

uj
vj
µi

=
f
−
f
a

j
j
ij

c
c
cj
i
j
i=1 j=1







n

µi
uj
vj 
+
bij
gj
− gj


ci
cj
cj
j =1


∗
∗
n
n
  (aij Fj + bij Gj )
|uj − vj |
≤
i =1

=−

j =1

In this section, drive–response synchronization of FMNN based
on linear control will be discussed. Let FMNN (1) be the master

L. Chen et al. / Neural Networks 71 (2015) 37–44

system, and the slave system is given by
n


Dα zi (t ) = −ci zi (t ) +

aij (zi (t ))fj (zj (t ))

j=1

+

n


bij (zi (t ))gj (zj (t − τ )) + Ii − ui (t ),

i ∈ N , (10)

j =1

where ui (t ) is a suitable controller to be designed latter.
The slave system is equivalent to the following differential
inclusion
Dα zi (t ) ∈ −ci zi (t ) +

n


co[aij (zj (t ))]fj (zj (t ))

j =1

+

n


co[bij (zj (t ))]gj (xj (t − τ )) + Ii − ui ,

t > 0, i ∈ N . (11)

j =1

Denote ei (t ) = zi (t ) − xi (t ), then the error systems between (11)
and (2) can be described by
Dα ei (t ) ∈ − ci zi (t ) − ci xi (t )



+

n



+

n





co[aij (zj (t ))]fj (zj (t )) − co[aij (xj (t ))]fj (xj (t ))



j =1

co[bij (zj (t ))]gj (zj (t − τ ))

j =1


− co[bij (xj (t ))]gj (xj (t − τ )) − ui
(12)
or equivalently, for i, j ∈ N, there exist measurable functions
a˜ ∗ij (ej (t )) ∈ co[aij (zj (t ))]fj (zj (t )) − co[aij (xj (t ))]fj (xj (t )),
b˜ ∗ij (ej (t − τ )) ∈ co[bij (zj (t ))]gj (zj (t − τ ))
− co[bij (xj (t ))]gj (xj (t − τ )),
such that
Dα ei (t ) = −ci ei (t ) +

n


a˜∗ ij (ej (t ))

j =1
n

+



b˜∗ ij (ej (t − τ )) − ui .

(13)

j =1

Obviously, synchronization between master system (1) and slave
(10) is equivalent to the asymptotic stability of error system (12)
or (13) with the suitable control law ui (t ). For this end, the external
control input is adopted as ui (t ) = ki ei (t ). Then the error system
can be described by
Dα ei (t ) = −(ci + ki )ei (t ) +

n


a˜∗ ij (ej (t ))

n


and applied to MFNN. Since similar method has not been well
developed for MFNN, to analyze stability of delayed MFNN is still a
formidable problem. As we all know, there are few results on global
asymptotic stability and synchronization for delayed MFNN in the
existing literatures. In the paper, by using the comparison theorem
for fractional-order linear delayed system, asymptotic stability and
synchronization criteria for delayed MFNN are proposed firstly.
Remark 2. The problem of finite-time stability of fractionalorder complex-valued memristor based neural networks with
time delays is investigated in non-Lyapunov point of view in
Ref. (Rakkiyappan et al., 2014). In fact, finite-time stability and
asymptotic stability are independent concepts, which neither
implies nor exclude each other. Here, the global asymptotic
stability of delayed MFNN is discussed firstly.
Remark 3. It is well known that the time delay is unavoidable
in artificial neural networks due to finite switching speeds of
the amplifiers, and it may cause oscillations or instability of
dynamic systems. So, taking time-delay into consideration is very
necessary and important. Refs. (Bao & Cao, 2015; Chen et al., 2014)
investigated the projective synchronization of MFNN, but without
considering time-delay. On the other hand, by using the method
presented in this paper, it is easy to obtain a controller designing
scheme for projective synchronization of delayed MFNN.
Remark 4. If memristor aij (xi ), bij (xi ) in the mathematical mode
(1) become constant, rather than depending on the state, i.e. the
values of the connection weights are not changed, then mode (1)
will be degenerated into general fractional-order neural networks
with delay, see Refs. (Chen et al., 2013; Wang et al., 2014, 2015). In
this case, the obtained results are new and still valid for fractionalorder neural networks with delay. It is obvious that results in
Ref. (Wang et al., 2015) are special case of Theorem 3.1.
Remark 5. If fractional-order α = 1, then system (1) will be reduced to an integer-order MNN with time delays. Correspondingly,
the results on asymptotic stability and synchronization in Theorems 3.1 and 3.2, respectively, will be reduced to that of integerorder delayed MNN model, which were discussed in Refs. (Wen
et al., 2013; Wu & Zeng, 2012; Zhang et al., 2012).
4. Numerical examples
Now, three numerical simulations to demonstrate the effectiveness and applicability of the proposed results are presented.
Example 1. Consider two-dimensional FMNN with the following
parameters

j=1

+

b˜∗ ij (ej (t − τ )).

(14)

j =1

a11 (x1 ) =

Theorem 3.2. Under Assumption 1, if controller feedback gain ki
satisfies


min ci + ki − Fi

1≤i≤n

n


j =1

a∗ji



 
n

> max Gi
1≤i≤n

41

b∗ji



a21 (x2 ) =

> 0,

(15)

j =1

then the synchronization between systems (1) and (10) is achieved.
Proof. The proof is similar to Theorem 1, we omit here.
Remark 1. Recently, with the help of constructing traditional
Lyapunov–Krasovskii functional, there are some results about
stability and synchronization of integer-order MNN with timedelay, but the method and these results could not be extended

b11 (x1 ) =

b21 (x2 ) =


1


,

|x1 (t )| < 1,


− ,
6

1


,

|x1 (t )| > 1,


− ,
5

1


,

|x2 (t )| > 1,


− ,
4

1


,

|x1 (t )| > 1,


− ,

|x2 (t )| > 1,

6
1

5
1

4
1

7
1
7

|x2 (t )| < 1,

|x1 (t )| < 1,

|x2 (t )| < 1,

a12 (x1 ) =

a22 (x2 ) =

b12 (x1 ) =

b22 (x2 ) =


1


,

|x1 (t )| < 1,


− ,
5

1


,

|x1 (t )| > 1,


− ,
8

1


,

|x2 (t )| > 1,


− ,
6

1


,

|x1 (t )| > 1,


− ,

|x2 (t )| > 1,

5
1

8
1

6
1

3
1
3

|x2 (t )| < 1,

|x1 (t )| < 1,

|x2 (t )| < 1,

42

L. Chen et al. / Neural Networks 71 (2015) 37–44

(1) with five initial values x(0) = (5 + 0.5i, −6 − 0.5i)T (i =
1, 2, 3, 4, 5) are depicted in Fig. 1.

Example 2. Consider three-dimensional FMNN (1) with the following parameters as the drive system
a11 (x1 ) =
a13 (x1 ) =
a22 (x2 ) =
a31 (x3 ) =
Fig. 1. Model (1) in Example 1 has a unique equilibrium point x∗ , which is globally
asymptotically stable.

c1 = 1, c2 = 1.2, α = 0.8, τ = 0.5. I1 = 1, I2 = 2.
Take the activation function as f1 (x) = f2 (x) = g1 (x) = g2 (x)
= tanh(x). Thus, it is easy to obtain
that

 i = 1(i = 11, 2).
Fni = G
Based on Theorem 1, min1≤i≤n ci − Fi j=1 a∗ji = 19
> 2 =
30

max1≤i≤n Gi j=1 b∗ji > 0. It follows from Theorem 3.1 that FMNN
is globally asymptotically stable. The simulation results of FMNN

 n



a33 (x3 ) =



2,
−2,



0.5,
−0.5,



1,
−1,



1.5,
−1.5,



1,
−1,

|x1 (t )| < 1,
|x1 (t )| > 1,
|x1 (t )| < 1,
|x1 (t )| > 1,
|x2 (t )| < 1,
|x2 (t )| > 1,
|x3 (t )| < 1,
|x3 (t )| > 1,
|x3 (t )| < 1,
|x3 (t )| > 1,

0.5, |x1 (t )| < 1,
−0.5, |x1 (t )| > 1,

2, |x2 (t )| < 1,
b21 (x2 ) =
−2, |x2 (t )| > 1,

1, |x2 (t )| < 1,
b23 (x2 ) =
−1, |x2 (t )| > 1,

b12 (x1 ) =




−1, |x1 (t )| < 1,
1, |x1 (t )| > 1,

1.5, |x2 (t )| < 1,
a21 (x2 ) =
−1.5, |x2 (t )| > 1,

2, |x2 (t )| < 1,
a23 (x2 ) =
−2, |x2 (t )| > 1,

2, |x3 (t )| < 1,
a32 (x3 ) =
−2, |x3 (t )| > 1,

1, |x1 (t )| < 1,
b11 (x1 ) =
−1, |x1 (t )| > 1,

1.5, |x1 (t )| < 1,
b13 (x1 ) =
−1.5, |x1 (t )| > 1,

1.5, |x2 (t )| < 1,
b22 (x2 ) =
−1.5, |x2 (t )| > 1,

2, |x3 (t )| < 1,
b31 (x3 ) =
−2, |x3 (t )| > 1,

a12 (x1 ) =

b

a

c

Fig. 2. The state synchronization trajectories of the master system (1) and slave system (10) with controller ui (t ) = 6ei (t ) (i = 1, 2, 3) in Example 2(a: x1 (t ) vs. x1 (t ); b:
x2 (t ) vs. z2 (t ) c: x3 (t ) vs. z3 (t )).

L. Chen et al. / Neural Networks 71 (2015) 37–44

43

Example 3. Consider the following fractional-order neural network of three neurons with ring structure and time delay

 α
D x1 (t ) = −c1 x1 (t ) + a11 sin(x1 (t )) + a12 sin(x2 (t ))



+ b11 tanh(x1 (t − τ )) + b12 tanh(x2 (t − τ )),


Dα x2 (t ) = −c2 x2 (t ) + a22 sin(x2 (t )) + a23 sin(x3 (t ))

+ b22 tanh(x2 (t − τ )) + b23 tanh(x3 (t − τ )),


Dα x3 (t ) = −c3 x3 (t ) + a31 sin(x1 (t )) + a33 sin(x3 (t ))




+ b31 tanh(x1 (t − τ )) + b33 tanh(x3 (t − τ )),

xi (t ) = xi (0), i = 1, 2, 3, t ∈ [−τ , 0],

(16)

where parameters of system (16) are chosen as α = 0.9, τ =
0.9, c1 = 5, a11 = 1, c2 = 5, a22 = −1, c3 = 6, a33 =
2, a12 = a23 = a31 = 0.8, b11 = b22 = b33 = 1 and b12 =
b23 = b31 = −2. It is easy to verify that
satisfy
the
 these

values
n
conditions of Theorem 3.1. i.e. min1≤i≤n ci − Fi j=1 |aji | = 3.2 >
3 = max1≤i≤n Gi j=1 |bji | . The initial values of x1 (0), x2 (0) and
x3 (0) are chosen as x1 (0) = 0.6, x2 (0) = 0.8 and x3 (0) = 1.
The convergence behavior is shown in Fig. 4. It is shown that the
solution of the system (16) converges to the equilibrium point 0.

 n

Fig. 3. Synchronization error trajectories of the drive and response systems with
controller ui (t ) = 6ei (t ) (i = 1, 2, 3) in Example 2.



5. Conclusions
Time delays are inevitable in hardware implementation of
neural networks, it is very important and necessary to consider
the dynamic behaviors of neural networks with delay. However, to
analyze global asymptotical stability of fractional-order nonlinear
delayed systems is very challenging. In this paper, by using
comparison theorem for a class of fractional-order linear delayed
systems, global asymptotical stability and synchronization of
memristor-based fractional-order delayed neural networks are
addressed, and corresponding criteria are proposed, respectively.
The obtained results are of great significance to the design of
memristor-based fractional-order neural networks in the field of
artificial intelligence.
Acknowledgments
Fig. 4. Time response curves of system (16) with α = 0.9 and τ = 0.9 in Example 3.

b32 (x3 ) =

3,
−3,



|x3 (t )| < 1,
|x3 (t )| > 1,

b33 (x3 ) =

1.5,
−1.5,



|x3 (t )| < 1,
|x3 (t )| > 1,

c1 = 5, c2 = 5.5, c3 = 6, order α = 0.9, τ = 0.8. Activation
function is chosen as f1 (x) = f2 (x) = f3 (x) = 21 (|1 + x| −
|1 − x|), g1 (x) = g2 (x) = g3 (x) = tanh(x). Corresponding response
system is defined as (10). By simple computation, if feedback gains
ki > 5 (i = 1, 2, 3
), the conditions
of Theorem 2 are
satisfied,


n
n
i.e. min1≤i≤n ci − Fi j=1 a∗ji = ki > 5 = max1≤i≤n Gi j=1 b∗ji .
It follows from Theorem 3.2 that drive system (1) and the
corresponding response system (10) are globally synchronized. In
numerical simulations, the initial states of the drive and response
systems are taken as x(0) = (1, 3, 2)T and z (0) = (1.2, 0.5, 1)T ,
respectively. Feedback gains are selected as ki = 6 (i = 1, 2, 3).
Fig. 2 shows that all the state trajectories of the master system (1)
and slave system (10) achieve synchronization with the proposed
controller ui (t ) = 6ei (t ) (i = 1, 2, 3). The time evolution of
synchronization error with initial value e(0) = (0.2, −2.5, −1)T
is shown in Fig. 3.
Particularly, if the memristive connection weights aij (xi ) and
bij (xi ) in (1) are not changed according to own state, i.e. the
connection weights are implemented by resistor not memristor,
then model (1) will be degenerated into fractional-order delayed
neural networks. In order to show our results are suitable for such
case, a numerical example proposed in Ref. (Wang et al., 2014) is
presented.

This work was supported by the National Natural Science
Fundation of China for Distinguished Young Scholar under
Grant No. 50925727, the National Natural Science Fundation
of China under Grant Nos. 61403115, 51177035,61272530 and
11072059, the Natural Science Foundation of Anhui Province (No.
1508085QF120) and the National Defense Advanced Research
Project Grant (No. C1120110004).
References
Adhikari, S. P., Yang, C. J., Kim, H., & Chua, L. O. (2012). Memristor bridge synapsebased neural network and its learning. IEEE Transactions on Neural Networks and
Learning Systems, 23(9), 1426–1435.
Anastasio, T. (1994). The fractional-order dynamics of brainstem vestibulooculomotor neurons. Biological Cybernetics, 72, 69–79.
Anastassiou, G. (2012). Fractional neural network approximation. Computers and
Mathematics with Applications, 64, 1655–1676.
Bao, H., & Cao, J. (2015). Projective synchronization of fractional-order memristorbased neural networks. Neural Networks, 63, 1–9.
Bondarenko, V. (2005). Information processing, memories, and synchronization in
chaotic neural network with the time delay. Complexity, 11(2), 39–52.
Caponetto, R. (2010). Fractional order systems: modeling and control applications.
Singapore: World Scientific.
Chandrasekar, A., Rakkiyappan, R., Cao, J., & Lakshmanand, S. (2014). Synchronization of memristor-based recurrent neural networks with two delay components based on second-order reciprocally convex approach. Neural Networks,
57, 79–93.
Chen, L., Chai, Y., Wu, R., Ma, T., & Zhai, H. (2013). Dynamic analysis of a class of
fractional-order neural networks with delay. Neurocomputing, 111, 190–194.
Chen, L., Qu, J., Chai, Y., Wu, R., & Qi, G. (2013b). Synchronization of a class of
fractional-order chaotic neural networks. Entropy, 15(8), 3265–3276.
Chen, J., Zeng, Z., & Jiang, P. (2014). Global Mittag-Leffler stability and synchronization of memristor-based fractional-order neural networks. Neural Networks, 51,
1–8.

44

L. Chen et al. / Neural Networks 71 (2015) 37–44

Chua, L. O. (1971). Memristor-the missing circuit element. IEEE Transactions on
Circuit Theory, 18(5), 507–519.
Deng, W., Li, C., & Lu, J. (2007). Stability analysis of linear fractional differential
system with multiple time delays. Nonlinear Dynamics, 48, 409–416.
Driscoll, T., Quinn, J., & Klein, S. (2010). Memristive adaptive filters. Applied Physics
Letters, 97(9), 093502.
Ebong, I. E., & Mazumder, P. (2012). CMOS and memristor-based neural network
design for position detection. Proceedings of the TEEE, 100(6), 2050–2060.
Filippov, A. F. (1988). Differential equations with discontinuous right-hand sides.
Dordrecht: Kluwer.
Guo, Z., Wang, J., & Yan, Z. (2015). Global exponential synchronization of two
memristor-based recurrent neural networks with time delays via static or
dynamic coupling. IEEE Transactions on Systems and Cybernetics-Systems, 45(2),
235–249.
Haken, H. (2006). Pattern recognition and synchronization in pulse-coupled neural
networks. Nonlinear Dynamics, 44(1–4), 269–276.
Huang, X., Zhao, Z., Wang, Z., & Li, Y. (2012). Chaos and hyperchaos in fractionalorder cellular neural networks. Neurocomputing, 94, 13–21.
Jiang, M., Wang, S., Mei, J., & Shen, Y. (2015). Finite-time synchronization control
of a class of memristor-based recurrent neural networks. Neural Networks, 63,
133–140.
Kaslika, E., & Sivasundaram, S. (2012). Nonlinear dynamics and chaos in fractionalorder neural networks. Neural Networks, 32, 245–256.
Li, N., & Cao, J. (2015). New synchronization criteria for memristor-based networks:
Adaptive control and feedback control schemes. Neural Networks, 61, 1–9.
Lundstrom, B., Higgs, M., Spain, W., & Fairhall, A. (2008). Fractional differentiation
by neocortical pyramidal neurons. Nature Neuroscience, 11, 1335–1342.
Molinari, M., Leggio, M., & Thaut, M. (2007). The cerebellum and neural networks
for rhythmic sensorimotor synchronization in the human brain Cerebellum, 6(1),
18–23.
Podlubny, I. (1999). Fractional differential equations. San Diego: Academic Press.
Rakkiyappan, R., Chandrasekar, A., Park, J. H., & Kwon, O. M. (2014). Exponential
synchronization criteria for Markovian jumping neural networks with timevarying delays and sampled-data control. Nonlinear Analysis. Hybrid Systems,
14, 16–37.
Rakkiyappan, R., Velmurugan, G., & Cao, J. (2014). Finite-time stability analysis of
fractional-order complex-valued memristor-based neural networks with time
delays. Nonlinear Dynamics, 78(4), 2823–2836.
Rakkiyappan, R., Velmurugan, G., & Cao, J. (2015). Stability analysis of memristorbased fractional-order neural networks with different memductance functions.
Cognitive Neurodynamics, 9(2), 145–177.
Saptarshi, D., & Indranil, P. (2012). Fractional order signal processing. Germany:
Springer.
Shin, S., Kim, K., & Kang, S. (2011). Memristor applications for programmable analog
ICs. IEEE Transactions on Nanotechnology, 10(2), 266–274.
Song, C., & Cao, J. D. (2014). Dynamics in fractional-order neural networks.
Neurocomputing, 142, 494–498.
Stamova, I. (2014). Global Mittag-Leffler stability and synchronization of impulsive
fractional-order neural networks with time-varying delays. Nonlinear Dynamics, 77(4), 1251–1260.

Strukov, D. B., Snider, G. S., Stewart, G. R., & Williams, R. S. (2008). The missing
memristor found. Nature, 453(7191), 80–83.
Thomas, A. (2013). Memristor-based neural networks. Journal of Physics D, 46(9),
093001.
Valerio, D. (2012). An introduction to fractional control (control engineering). UK:
Institution of Engineering and Technology.
Wang, L. M., & Shen, Y. (2014). New results on passivity analysis of memristor-based
neural networks with time-varying delays. Neurocomputing, 144, 208–214.
Wang, L., & Shen, Y. (2015). Design of controller on synchronization of memristorbased neural networks with time-varying delays. Neurocomputing, 147,
372–379.
Wang, H., Yu, Y., & Wen, G. (2014). Stability analysis of fractional-order Hopfield
neural networks with time delays. Neural Networks, 55, 98–109.
Wang, H., Yu, Y. G., Wen, G. G., Zhang, S., & Yu, J. (2015). Global stability analysis
of fractional-order Hopfield neural networks with time delay. Neurocomputing,
154, 15–23.
Wen, S., Bao, G., Zeng, Z., Chen, Y., & Huang, T. (2013). Global exponential
synchronization of memristor-based recurrent neural networks with timevarying delays. Neural Networks, 48, 195–203.
Wen, S., Zeng, Z., Huang, T., & Chen, Y. (2013b). Passivity analysis of memristorbased recurrent neural networks with time-varying delays. Journal of the
Franklin Institute, 350(8), 2354–2370.
Wu, A., Wen, S., & Zeng, Z. (2012). Synchronization control of a class of memristorbased recurrent neural networks. Information Sciences, 183(1), 106–116.
Wu, A., & Zeng, Z. (2012). Dynamic behaviors of memristor-based recurrent neural
networks with time-varying delays. Neural Networks, 36, 1–10.
Yan, H., Choe, H., Nam, S., Hu, Y., Das, S., Klemic, J., Ellenbogen, J., & Lieber, C. (2011).
Programmable nanowire circuits for nanoprocessors. Nature, 470(7333),
240–244.
Yang, J., Strukov, D., & Stewart, D. (2013). Memristive devices for computing. Nature
Nanotechnology, 8, 13C24.
Yu, J., Hu, C., Jiang, H., & Fan, X. (2014). Projective synchronization for fractional
neural networks. Neural Networks, 49, 87–95.
Zhang, G., & Shen, Y. (2014). Exponential synchronization of delayed memristorbased chaotic neural networks via periodically intermittent control. Neural
Networks, 55, 1–10.
Zhang, G., Shen, Y., & Sun, J. (2012). Global exponential stability of a class
of memristor-based recurrent neural networks with time-varying delays.
Neurocomputing, 97, 149–154.
Zhang, G., Shen, Y., Yin, Q., & Sun, J. (2013). Global exponential periodicity and
stability of a class of memristor-based recurrent neural networks with multiple
delays. Information Sciences, 232, 386–396.
Zhang, S., Yu, Y. G., & Wang, H. (2015). Mittag-Leffler stability of fractional-order
Hopfield neural networks. Nonlinear Analysis. Hybrid Systems, 16, 104–121.
Zhou, J., Chen, T., & Xiang, L. (2005). Chaotic Lag synchronization of coupled delayed
neural networks and its applications in secure communication. Circuits Systems
and Signal Processing, 24(5), 599–613.

