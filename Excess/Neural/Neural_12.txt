Neural Networks 71 (2015) 76–87

Contents lists available at ScienceDirect

Neural Networks
journal homepage: www.elsevier.com/locate/neunet

OCReP: An Optimally Conditioned Regularization for pseudoinversion
based neural training
Rossella Cancelliere a,∗ , Mario Gai b , Patrick Gallinari c , Luca Rubini a
a

University of Turin, Department of Computer Sciences, C.so Svizzera 185, 10149 Torino, Italy

b

National Institute of Astrophysics, Astrophys. Observ. of Torino, Pino T.se (TO), Italy

c

Laboratory of Computer Sciences, LIP6, Univ. Pierre et Marie Curie, Paris, France

article

info

Article history:
Received 11 November 2014
Received in revised form 27 July 2015
Accepted 30 July 2015
Available online 12 August 2015
Keywords:
Regularization parameter
Condition number
Pseudoinversion
Numerical instability

abstract
In this paper we consider the training of single hidden layer neural networks by pseudoinversion, which,
in spite of its popularity, is sometimes affected by numerical instability issues. Regularization is known
to be effective in such cases, so that we introduce, in the framework of Tikhonov regularization, a
matricial reformulation of the problem which allows us to use the condition number as a diagnostic tool
for identification of instability. By imposing well-conditioning requirements on the relevant matrices,
our theoretical analysis allows the identification of an optimal value for the regularization parameter
from the standpoint of stability. We compare with the value derived by cross-validation for overfitting
control and optimization of the generalization performance. We test our method for both regression and
classification tasks. The proposed method is quite effective in terms of predictivity, often with some
improvement on performance with respect to the reference cases considered. This approach, due to
analytical determination of the regularization parameter, dramatically reduces the computational load
required by many other techniques.
© 2015 Elsevier Ltd. All rights reserved.

1. Introduction
In past decades Single Layer Feedforward Neural Networks
(SLFN) training was mainly accomplished by iterative algorithms
involving the repetition of learning steps aimed at minimizing
the error functional over the space of network parameters. These
techniques often gave rise to methods slow and computationally
expensive.
Researchers therefore have always been motivated to explore
alternative algorithms and recently some new techniques based on
matrix inversion have been developed. In the literature, they were
initially employed to train radial basis function neural networks
(Poggio & Girosi, 1990a; Lowe, 1989): the idea of using them also
for different neural architectures was suggested for instance in Pao,
Park and Sobajic (1994), Cancelliere (2001).
The work by Huang et al. (see for instance Huang, Zhu, & Siew,
2006) gave rise to a great interest in neural network community:
they presented the technique of Extreme Learning Machine (ELM)
for which SLFNs with randomly chosen input weights and hidden

∗

Corresponding author.
E-mail address: cancelli@di.unito.it (R. Cancelliere).

http://dx.doi.org/10.1016/j.neunet.2015.07.015
0893-6080/© 2015 Elsevier Ltd. All rights reserved.

layer biases can learn sets of observations with a desired precision,
provided that activation functions in the hidden layer are infinitely
differentiable. Besides, because of the use of linear output neurons,
output weights determination can be brought back to linear
systems solution, obtained via Moore–Penrose generalized inverse
(or pseudoinverse) of the hidden layer output matrix; so doing
iterative training is no more required.
Such techniques appear anyway to require more hidden units
with respect to conventional neural network training algorithms to
achieve comparable accuracy, as discussed in Yu and Deng (2012).
Many application-oriented studies in the last years have been
devoted to the use of these single-pass techniques, easy to implement and computationally fast; some are described e.g. in Ajorloo,
Manzuri-Shalmani, and Lakdashti (2007), Kohno, Kawamoto, and
Inouye (2010), Nguyen, Pham, and Dang (2010) and Cancelliere,
Gai, Artières, and Gallinari (2012). A yearly conference is currently
being held on the subject, the International Conference on Extreme
Learning Machines, and the method is currently dealt with in some
journal special issue, e.g. Soft Computing (Wang, Wang & Huang,
2012) and the International Journal of Uncertainty, Fuzziness and
Knowledge-Based Systems (Wang, 2013).
Because of the possible presence of singular and almost singular matrices, pseudoinversion is known to be a powerful but

R. Cancelliere et al. / Neural Networks 71 (2015) 76–87

numerically unstable method: nonetheless in the neural network
community it is often used without singularity checks and evaluated through approximated methods.
In this paper we improve on the theoretical framework using singular value analysis to detect the occurrence of instability.
Building on Tikhonov regularization, which is known to be effective in this context (Golub, Hansen, & O’Leary, 1999), we present a
technique, named Optimally Conditioned Regularization for Pseudoinversion (OCReP), that replaces unstable, ill-posed problems
with well-posed ones.
Our approach is based on the formal definition of a new
matricial formulation that allows the use of condition number
as diagnostic tool. In this context an optimal value for the
regularization parameter is analytically derived by imposing wellconditioning requirements on the relevant matrices.
The issue of regularization parameter choice has often been
identified as crucial in literature, and dealt with in a number
of historical contributions: a conservative guess might put its
published estimates at several dozens. Some of the most relevant
works are mentioned in Section 2, where the related theoretical
background is recalled.
Its determination, mainly aimed at overfitting control, has often
been done either experimentally via cross-validation, requiring
heavy computational training procedures, or analytically under
specific conditions on the matrices involved, sometimes hardly
applicable to real datasets, as discussed in Section 2.
In Section 3 we present the basic concepts concerning input
and output weights setting, and we recall the main ideas on illposedness, regularization and condition number.
In Section 4 our matricial framework is introduced, and
constraints on condition number are imposed in order to derive
the optimal value for the regularization parameter.
In Section 5 our diagnosis and control tool is tested on some
applications selected from the UCI database and validated by
comparison with the framework regularized via cross-validation
and with the unregularized one.
The same datasets are used in Section 6 to test the technique
effectiveness: our performance is compared with those obtained
in other regularized frameworks, originated in both statistical and
neural domains.
2. Recap on ordinary least-square and ridge regression estimators
As stated in the introduction, pseudoinversion based neural
training brings back output weights determination to linear
systems solution: in this section we recall some general ideas on
this issue, that in next sections will be specialized to deal with SLFN
training.
The estimate of β through ordinary least-squares (OLS)
technique is a classical tool for solving the problem
Y = X β + ϵ,

(1)

where Y and ϵ are column n-vectors, β is a column p-vector and X
is an n × p matrix; ϵ is random, with expectation value zero and
variance σ 2 .
In Hoerl (1962) and Hoerl and Kennard (1970) the role of
ˆ
ordinary ridge regression (ORR) estimator β(λ)
as an alternative
to the OLS estimator in the presence of multicollinearity is deeply
analyzed. In statistics, multicollinearity (also collinearity) is a
phenomenon in which two or more predictor variables in a
multiple regression model are highly correlated, meaning that
one can be linearly predicted from the others with a non-trivial
degree of accuracy. In this situation, the coefficient estimates of
the multiple regression may change erratically in response to small
changes in the model or the data.

77

It is known in literature that there exist estimates of β with
smaller mean square error (MSE) than the unbiased, or Gauss–
Markov, estimate (Berger, 1976; Golub, Heath, & Wahba, 1979)

ˆ 0) = (X T X )−1 X T Y .
β(

(2)

Allowing for some bias may result in a significant variance
reduction: this is known as the bias–variance dilemma (see e.g.
Geman, Bienenstock, & Doursat, 1992 and Tibshirani, 1996), whose
effects on output weights determination will be deepened in
Section 3.2.
Hereafter we focus on the one parameter family of ridge
ˆ
estimates β(λ)
given by

ˆ
β(λ)
= ( X T X + nλ I ) − 1 X T Y .

(3)

ˆ
It can be shown that β(λ)
is also the solution to the problem of
finding the minimum over β of
1
n

∥Y − X β∥22 + λ∥β∥22 ,

(4)

which is known as the method of regularization in the approximation theory literature (Golub et al., 1979); basing on it we will develop the theoretical framework for our work in the next sections.
There has always been a substantial amount of interest in
estimating a good value of λ from the data: in addition to those
already cited in this section a non-exhaustive list of well known
or more recent papers is e.g. Hoerl and Kennard (1976), Kibria
(2003), Khalaf and Shukur (2005), Lawless and Wang (1976),
Mardikyan and Cetin (2008), McDonald and Galarneau (1975),
Nordberg (1982) and Saleh and Kibria (1993).
A meaningful review of these formulations is provided in
Dorugade and Kashid (2010). They first define the matrix T such
that T T X T XT = Λ (Λ = diag(λ1 , λ2 , . . . λp ) contains the eigen
values of the matrix X T X ); then they set Z = XT and α = T T β ,
and show that a great amount of different methods require the OLS
estimates of α and σ

αˆ = (Z T Z )−1 Z T Y ,
σˆ 2 =

(5)

Y Y − αˆ Z Y
T

T

T

(6)

n−p−1

to define effective ridge parameter values. It is important to note
that often specific conditions on data are needed to evaluate these
estimators.
In particular this applies to the expressions of the ridge
parameter proposed by Hoerl and Kennard (1970) and Kibria
(2003), that share the characteristic of being functions of the ratio
between σˆ 2 and a function of αˆ ; they will be used for comparison
with our proposed method in Section 6.
The alternative technique of generalized cross-validation (GCV)
proposed by Golub et al. (1979) provides a good estimate of λ from
the data as the minimizer of
V (λ) =

∥I − A(λ)Y ∥22

1
n

1
n

Trace(I − A(λ))

2 ,

(7)

2

where
A(λ) = X (X T X + nλI )−1 X T .

(8)

This solution is particularly interesting, since it does not require
an estimate of σ 2 : because of this, it will be one term of comparison
with our experimental results in Section 6.
In the next section we will show how the problem of finding
a good solution to (1) applies to the context of pseudoinversion
based neural training, specializing the involved relevant matrices
to deal with this issue.

78

R. Cancelliere et al. / Neural Networks 71 (2015) 76–87

3. Main ideas on regularization and condition number theory
3.1. Generalized inverse matrix for weights setting
We deal with a standard SLFN with L input neurons, M hidden
neurons and Q output neurons, non-linear activation functions φ
in the hidden layer and linear activation functions in the output
layer.
Considering a dataset of N distinct training samples (xj , tj ),
where xj ∈ RL and tj ∈ RQ , the learning process for a SLFN aims
at producing the matrix of desired outputs T ∈ RN ×Q when the
matrix of all input instances X ∈ RN ×L is presented as input.
As stated in the introduction, in the pseudoinverse approach the
matrix of input weights and hidden layer biases is randomly chosen
and no longer modified: we name it C . After having fixed C , the
hidden layer output matrix H = φ(XC ) is completely determined;
we underline that since H ∈ RN ×M , it is not invertible.
The use of linear output neurons allows to determine the output
weight matrix W ∗ in terms of the OLS solution to the problem
T = H W + ϵ , in analogy with Eq. (1). Therefore from Eq. (2), we
have
W ∗ = (H T H )−1 H T T .

(9)

According to (Bishop, 2006; Penrose & Todd, 1956)
W = H +T .
∗

(10)

H + is the Moore–Penrose pseudoinverse (or generalized
inverse) of matrix H, and it minimizes the cost functional
ED = ∥HW − T ∥22 .

(11)

Singular value decomposition (SVD) is a computationally
simple and accurate way to compute the pseudoinverse (see for
instance Golub & Van Loan, 1996), as follows.
Every matrix H ∈ RN ×M can be expressed as
H = UΣV T ,

(12)
N ×N

M ×M

where U ∈ R
and V ∈ R
are orthogonal matrices and
Σ ∈ RN ×M is a rectangular diagonal matrix (i.e. a matrix with
σih = 0 if i ̸= h); its elements σii = σi , called singular values, are
non-negative. A common convention is to list the singular values
in descending order, i.e.

σ1 ≥ σ2 ≥ · · · ≥ σp > 0

(13)

where p = min{N , M }, so that Σ is uniquely determined.
The SVD of H is then used to obtain the pseudoinverse matrix
H +:
H + = V Σ +U T ,

(14)

where Σ ∈ R
is again a rectangular diagonal matrix whose
elements σi+ are obtained by taking the reciprocal of each corresponding element: σi+ = 1/σi (see also Rao & Mitra, 1971). From
Eq. (9) we than have:
+

M ×N

W ∗ = V Σ +U T T ,

(15)

Remark. An interesting case occurs when only k < p elements in
Eq. (13) are non-zero, i.e. σk+1 = · · · = σp = 0; in this case the
rank of matrix H is k and Σ + is defined as:

Σ + = diag(1/σ1 , . . . , 1/σk , 0, . . . , 0) ∈ RM ×N ,
as shown for instance in Golub and Van Loan (1996).

This is also often done in practice, for computational reasons,
for elements smaller than a predefined threshold, thus actually
computing an approximated version of the pseudoinverse matrix
H +.
This approach is for example used by default for pseudoinverse
evaluation by means of the Matlab pinv function,1 because the
tool is widely used by many scientists for example in ELM context,
each time that it is applied blindly, i.e. without having decided
at what threshold to zero the small σi , an approximation a priori
uncontrolled is introduced in H + evaluation.
3.2. Stability and generalization properties of regularization algorithms
A key property for any learning algorithm is stability: the
learned mapping has to suffer only small changes in presence of
small perturbations (for instance the deletion of one example in
the training set).
Another important property is generalization: the performance
on the training examples (empirical error) must be a good indicator
of the performance on future examples (expected error), that is,
the difference between the two must be small. An algorithm that
guarantees good generalization predicts well if its empirical error
is small.
Many studies in literature dealt with the connection between
stability and generalization: the notion of stability has been
investigated by several authors, e.g. by Devroye and Wagner (1979)
and Kearns and Ron (1999).
Poggio et al. in Mukherjee, Niyogi, Poggio, and Rifkin (2003)
introduced a statistical form of leave-one-out stability, named
CVEEE loo , building on a cross-validation leave-one-out stability endowed with conditions on stability of both expected and empirical
errors; they demonstrated that this condition is necessary and sufficient for generalization and consistency of the class of empirical
risk minimization (ERM) learning algorithms, and that it is also a
sufficient condition for generalization for not ERM algorithms (see
also Poggio, Rifkin, Mukherjee, & Niyogi, 2004).
To turn an original instable, ill-posed problem into a well-posed
one, regularization methods of the form (4) are often used (Badeva
& Morozov, 1991) and among them, Tikhonov regularization is one
of the most common (Tikhonov, 1963; Tikhonov & Arsenin, 1977).
It minimizes the error functional
E ≡ ED + ER = ∥HW − T ∥22 + ∥Γ W ∥22 ,

(17)

obtained adding to the cost functional ED in Eq. (11) a penalty
term ER that depends on a suitably chosen Tikhonov matrix Γ .
This issue has been discussed in its applications to neural networks
in Poggio and Girosi (1990b), and surveyed in Girosi, Jones, and
Poggio (1995) and Haykin (1999).
Besides, Bousquet and Elisseeff (2002) proposed the notion
of uniform stability to characterize the generalization properties
of an algorithm. Their results state that Tikhonov regularization
algorithms are uniformly stable and that uniform stability implies
good generalization (Mukherjee, Niyogi, Poggio, & Rifkin, 2006).
Regularization thus introduces a penalty function that not only
improves on stability, making the problem less sensitive to initial
conditions, but it is also important to contain model complexity
avoiding overfitting.
The idea of penalizing by a square function of weights is also
well known in neural literature as weight decay: a wide amount of
articles have been devoted to this argument, and more generally
to the advantage of regularization for the control of overfitting.

(16)
1 http://www.mathworks.com/help/matlab/ref/pinv.html.

R. Cancelliere et al. / Neural Networks 71 (2015) 76–87

Among them we recall (Bishop, 2006; Fu, 1998; Gallinari & Cibas,
1999; Girosi et al., 1995; Hastie, Tibshirani, & Friedman, 2009;
Tibshirani, 1996).
√
A frequent choice is Γ = γ I, to give preference to solutions
with smaller norm (Bishop, 2006), so Eq. (17) can be rewritten as
E ≡ ED + ER = ∥HW − T ∥22 + γ ∥W ∥22 .

(18)

ˆ = minW (E ) the regularized solution of (18): it
We define W
belongs to the family of ridge estimates described by Eq. (3) and
can be expressed as
ˆ = (H T H + γ I )−1 H T T
W

(19)

or, as shown in Fuhry and Reichel (2012) as

ˆ = VDU T T .
W

σi
.
σ +γ
2
i

(21)

We remark on the difference between the minima of the regularized and unregularized error functionals. Increasing values of
the regularization parameter γ induce larger and larger departure
of the former (Eq. (19)) from the latter (Eq. (9)). Thus, the regularization process increases the bias of the approximating solution and reduces its variance, as discussed about the bias–variance
dilemma in Section 2.
A suitable value for the Tikhonov parameter γ has therefore to
derive from a compromise between having it sufficiently large to
control the approaching to zero of σi in Eq. (21), while avoiding an
excess of the penalty term in Eq. (18). Its tuning is therefore crucial.
3.3. Condition number as a measure of ill-posedness
The condition number of a matrix A ∈ RN ×M is the number µ(A)
defined as

µ(A) = ∥A∥ ∥A+ ∥

(22)

where ∥·∥ is any matrix norm. If the columns (rows) of A are
linearly independent, e.g. in case of experimental data matrices,
then A+ is a left (right) inverse of A, i.e. A+ A = IN (AA+ = IM ). The
Cauchy–Schwarz inequality in this case then provides µ(A) ≥ 1;
besides, µ(A) ≡ µ(A+ ).
Matrices are said to be ill-conditioned if µ(A) ≫ 1.
If ∥·∥2 norm is used, then

µ(A) =

σ1 (A)
,
σp (A)

method fits within this context. We will see that it specifically
aims at analytically determining the value of the γ parameter that
minimizes the conditioning of the regularized hidden layer output
ˆ is stable in the sense of Eq. (2.9) of
matrix so that the solution W
Mukherjee et al. (2006).
In the next section, we will derive the optimal value of the
regularization parameter γ according to this stability criterion
(minimum condition number).
The experimental results presented in Sections 5 and 6 will
evidence that our quest for stable solutions allows us to also
achieve good generalization and predictivity. A comparison will be
made to this purpose with the performance obtained when γ is
determined via the standard cross-validation approach, aimed at
overfitting control and generalization performance optimization.

(20)

V and U are from the singular value decomposition of H
(Eq. (12)) and D ∈ RM ×N is a rectangular diagonal matrix whose
elements, built using the singular values σi of matrix Σ , are:
Di =

79

(23)

where σ1 and σp are the largest and smallest singular values of A
respectively.
From Eq. (23) we can easily understand that large condition
numbers µ(A) suggest the presence of very small singular values
(i.e. of almost singular matrices), whose numerical inversion,
required to evaluate Σ + and the unregularized solution W ∗ , is a
cause of instability.
From numeric linear algebra we also know that if the condition
number is large the problem of finding least-squares solutions to
the corresponding system of linear equations is ill-posed, i.e. even
a small perturbation in the data can lead to huge perturbations in
the entries of solution (see Golub & Van Loan, 1996).
According to Mukherjee et al. (2006) the stability of Tikhonov
regularization algorithms can also be characterized using the
classical notion of condition number: our proposed regularization

4. Conditioning of the regularized matricial framework
For convenient implementation of our diagnostics, and building
on Eq. (20), we propose an original matricial framework in which
to develop our study tool with the following definition.
Definition 1. We define the matrix
H reg ≡ VDU T

(24)

as the regularized hidden layer output matrix of the neural
network.
This allows us to rewrite Eq. (20) as

ˆ = H reg T ,
W

(25)

for similarity with Eq. (9).
By construction, H reg is decomposed in three matrices according
to the SVD framework, and its singular values are provided by Eq.
(21) as a function of the singular values σi of H.
This new regularized matricial framework makes easier the
comparison of the properties of H reg with those of the corresponding unregularized matrix H + . In fact, when unregularized pseudoinversion is used, nothing prevents the occurrence of very small
singular values that make numerically instable the evaluation of
H + (see Eq. (14)). On the contrary, even in presence of very small
values σi of the original unregularized problem, a careful choice of
the parameter γ allows to tune the singular values Di of the regularized matrix H reg , preventing numerical instability.
4.1. Condition number definition
According to Eq. (23), we define the condition number of H reg
as:

µ(H reg ) =

Dmax
Dmin

(26)

where Dmax and Dmin are the largest and smallest singular values of
H reg .
The shape of the functional relation σ /(σ 2 + γ ) that links
regularized and unregularized singular values, defined through
Eq. (21), is shown in Fig. 1 for three different values of γ .
The curves are non-negative, because σ > 0 and γ > 0, and
√
have only one maximum, with coordinates ( γ ; 2√1 γ ).
A few pairs of corresponding values (Di , σi ) are marked by dots
on each curve.
For the sake of the determination of µ(H reg ) we are interested
in evaluating Dmax and Dmin of H reg over the finite, discrete range
[σ1 , σ2 , . . . , σp ].

80

R. Cancelliere et al. / Neural Networks 71 (2015) 76–87

Fig. 2. Regularized condition number vs. β .

Fig. 1. Example of regularized/unregularized singular values relationship via Eq.
(21).

The value Dmax is reached in correspondence to a given singular
value of H, a priori not known, that we label σmax , so that:
Dmax =

σmax
.
2
σmax
+γ

(27)

The variation of γ has the effect of changing the curve and
shifting its maximum point within the interval [σ1 , σp ]. Therefore,
σmax can coincide with any singular value of H from Eq. (13),
including the extreme ones.
Conversely, we now demonstrate that Dmin can only be reached
in correspondence to σ1 or σp (or both when coincident).
Theorem 4.1. The minimum singular value Dmin of matrix H reg can
only be reached in correspondence to the largest singular value σ1 or
to the smallest singular value σp of the unregularized matrix H (or
both).
Proof. Without loss of generality, we can express γ as a function
of σ1 σp , i.e. γ = βσ1 σp , where β is a real positive value. By
replacement in Eq. (21), we get
D1 =

1

σ1 + βσp

,

Dp =

1

σp + βσ1

.

To establish their ordering, we evaluate the difference ∆ of their
inverses:

∆=

1
D1

−

1
Dp

= (σ1 + βσp ) − (σp + βσ1 ) = (1 − β)(σ1 − σp ).

Recalling that σ1 − σp > 0, we can distinguish three cases:
Case1, β > 1 (γ > σ1 σp ) → ∆ < 0 → D1 > Dp .
Because of the Di distribution shape, Dp is also the
minimum among all values Di , so that Dmin ≡ Dp .
Case2, β < 1 (γ < σ1 σp ) → ∆ > 0 → D1 < Dp .
Then, D1 is also the minimum among all values Di , so that
Dmin ≡ D1 .
Case3, β = 1 (γ = σ1 σp ) → ∆ = 0 → D1 = Dp .
Thus, D1 and Dp are both minima, so that Dmin ≡ D1 =
Dp .
4.2. Condition number evaluation
The result by Theorem 4.1 allows us to find, according to Eq.
(26), the following expressions for µ(H reg ):

Case 1, β > 1:

µ(H reg ) =

Dmax
Dp

=

σmax (σp + βσ1 )
.
2
σmax
+ βσ1 σp

=

σmax (σ1 + βσp )
.
2
σmax
+ βσ1 σp

Case 2, β < 1:

µ(H reg ) =

Dmax
D1

Case 3, β = 1:

µ(H reg ) =

Dmax
Dp

=

Dmax
D1

=

σmax (σp + σ1 )
.
2
σmax
+ σ1 σp

Bearing in mind that well-conditioned problems are characterized by small condition numbers, we now will look for the β
parameter values which, in the three cases above, make the regularized condition number smaller.
In Case 1, µ(H reg ) is an increasing function of β , so that in its
domain, i.e. (1, ∞), its minimum value is reached when β → 1+ .
On the contrary, in Case 2, µ(H reg ) is a decreasing function of β ,
so that in its domain, i.e. (0, 1), the minimum is reached when
β → 1− .
Fig. 2 shows the function behavior over the whole domain.
Both cases have a common limit:
lim µ(H reg ) = lim µ(H reg ) =

β→1+

β→1−

σmax (σp + σ1 )
.
2
σmax
+ σ1 σp

(28)

Such value is just that provided by Case 3, which can therefore
be considered the best possible choice to minimize the condition
number.
Thus our quest for the best possible conditioning for the matrix
H reg identifies an explicit optimal value for the regularization
parameter γ :

γ = σ1 σp .

(29)

5. Simulation and discussion
For the numerical experimentation, we use eight benchmark
datasets from the UCI repository (Bache & Lichman, 2013) listed in
Table 1. All simulations are carried out in Matlab 7.3 environment.
The performance is assessed by statistics over a set of 50
different extractions of input weights, computing either the
average RMSE (for regression tasks) or the average percentage of
misclassification rate (for classification tasks) on the test set. Either
quantity is labeled ‘‘Err’’ in the tables summarizing our results.

R. Cancelliere et al. / Neural Networks 71 (2015) 76–87

81

Fig. 3. Test error trends for regression datasets as a function of the values of γ over the selected cross-validation range (red dots): the cross-validation selected γ is the
black square; the proposed γ from OCReP is the blue circle. (For interpretation of the references to color in this figure legend, the reader is referred to the web version of
this article.)
Table 1
The UCI datasets and their characteristics.
Dataset

Type

N. Instances

N. Attributes

N. Classes

Abalone
Machine Cpu
Delta Ailerons
Housing
Iris
Diabetes
Wine
Segment

Regression
Regression
Regression
Regression
Classification
Classification
Classification
Classification

4177
209
7129
506
150
768
178
2310

8
6
5
13
4
8
13
19

–
–
–
–
3
2
3
7

The error standard deviation (labeled ‘‘Std’’) is also computed to
evidence the dispersion of experimental results.
Our regularization strategy, labeled Optimally Conditioned Regularization for Pseudoinversion (OCReP), is verified by simulation
against the common approach in which cross-validation is used
(i) to determine the regularization parameter γ at a fixed high
number of hidden neurons and (ii) to perform also hidden neurons
number optimization, respectively in Sections 5.1 and 5.2.
A discussion of the effectiveness of OCReP in terms of
minimization of the condition number of the involved matrices is
done in Section 5.3.
5.1. OCReP performance assessment: fixed number of hidden units
In this section we compare OCReP with a regularization approach in which γ is selected by a cross-validation scheme, which
is typically used for control of under/overfitting and optimization of the model generalization performance. A 70%/30% split

between training and test set is applied; then, a three-fold crossvalidation search on the training set identifies the best γ by best
performance on the validation set, over the set of 50 values of
γ [10−25 , 10−24 , . . . , 1025 ].
For the sake of comparison, a fixed, high number of hidden
units M is used, selected according to dimension and complexity
of the datasets. For the three datasets Machine Cpu, Iris and Wine
the simulation is performed for 50 and 100 hidden neurons; for
Abalone, Delta Ailerons, Housing and Diabetes, we use 50, 100, 200
and 300 neurons; for Segment, we use 1000 and 1500 units.
Figs. 3 and 4 (respectively for regression and classification
datasets) show average test errors as a function of the sampled
values of γ (red dots); the standard deviation is shown as an error
bar. Our proposed optimal γ is evidenced as a blue circle, whereas
the value of γ selected by cross-validation is shown as a black
square. The results are in each case related to the highest number
of neurons experimented.
The horizontal axis has been zoomed in onto the region of
interest, i.e. [10−10 , 105 ].
It may be noted that the performance from OCReP and crossvalidation are comparable, and also close to the experimental
minimum. This may be interpreted as good predictivity for both
algorithms.
Also, we remark that the error bars, i.e. experimental result
dispersion, is large for small values of γ , consistently with
expectations on ineffective regularization.
The numerical results have been reported in Tables 2–4
according to the grouping based on dimension and complexity of
the datasets.

82

R. Cancelliere et al. / Neural Networks 71 (2015) 76–87

Fig. 4. Test error trends for classification datasets as a function of the values of γ over the selected cross-validation range (red dots): the cross-validation selected γ is the
black square; the proposed γ from OCReP is the blue circle. (For interpretation of the references to color in this figure legend, the reader is referred to the web version of
this article.)
Table 2
Comparison of OCReP vs. cross-validation at fixed number of hidden neurons for
small size datasets.

OCReP
50
Cross-val.
M
OCReP
100
Cross-val.

Iris

Wine

Machine Cpu

Err.
Std
Err.
Std

1.51
1.13
2.13
0.77

2.98
1.75
3.37
2.27

31.21
1.1
31.1
1.02

Err.
Std
Err.
Std

2.53
0.77
2.17
0.31

1.39
1.19
1.88
1.88

34.13
01.68
30.94
0.69

For each dataset and selected number of hidden neurons M,
the best test error is evidenced in bold, whenever the difference
is statistically significant.2
Thus, for example, on Iris the best performance is achieved
using 50 neurons by OCReP, and with 100 neurons by crossvalidation. In some cases, e.g. Wine (50 neurons), there is no clear
winner from statistical considerations, i.e. the best results are
comparable, within the errors.
From the above results it appears that cross-validation has
better test error performance on a number of datasets slightly
higher, at fixed number of hidden neurons. However, it is
important to evidence that the use of OCReP allows to save the
hundreds of pseudoinversion steps required by cross-validation,
which is a crucial issue for practical implementation.

2 The Student’s t-test has been used for assessing the statistical significance
through determination of the confidence intervals related to 99% confidence level.

Table 3
Comparison of OCReP vs. cross-validation at fixed number of hidden neurons for
large size datasets.
Segment
OCReP

Err.
Std

2.53
0.77

Cross-val.

Err.
Std

2.17
0.31

OCReP

Err.
Std

4.41
0.45

Cross-val.

Err.
Std

3.97
0.35

1000
M

1500

5.2. OCReP performance assessment: variable number of hidden units
In order to pursue the double aim of performance and hidden
units optimization, a first interesting step is to give a look to the
variation as a function of hidden layer dimension of error trends
of unregularized models (i.e. models whose output weights are
evaluated according to Eq. (10)).
A context widely used among researchers using such techniques (see e.g. Helmy & Rasheed, 2009 and Huang et al., 2006)
is to use input weights distributed according to a random uniform
distribution in the interval (−1, 1), and sigmoidal activation functions for hidden neurons: hereafter we name this framework Sigmunreg.
Figs. 5 and 6 show, respectively for regression and classification
datasets, the average test error values, (over 50 different input
weights selections) for both OCReP (blue line) and Sigm-unreg
(red line) as a function of the number of hidden nodes, which

R. Cancelliere et al. / Neural Networks 71 (2015) 76–87

83

Table 4
Comparison of OCReP vs. cross-validation at fixed number of hidden neurons for medium size datasets. For Delta Ailerons,
average errors and standard deviations have to be multiplied by 10−4 .

OCReP
50
Cross-val.
OCReP
100
Cross-val.

M

OCReP
200
Cross-val.
OCReP
300
Cross-val.

Abalone

Delta Ailerons

Housing

Diabetes

Err.
Std
Err.
Std

2.22
0.016
2.13
0.017

1.64
0.0051
1.59
0.0073

5.54
0.12
4.79
0.37

26.01
0.604
26.79
0.814

Err.
Std
Err.
Std

2.15
0.007
2.11
0.006

1.62
0.004
1.58
0.0036

5.17
0.08
4.49
0.28

25.66
0.608
25.71
0.608

Err.
Std
Err.
Std

2.12
0.003
2.11
0.003

1.59
0.0031
1.61
0.0096

4.62
0.09
4.30
0.27

25.13
0.445
25.79
0.443

Err.
Std
Err.
Std

2.113
0.03
2.114
0.003

1.58
0.0018
1.60
0.0042

4.24
0.13
4.18
0.23

24.26
0.689
25.66
0.456

Fig. 5. Test error trends for regression datasets: OCReP vs. unregularized pseudoinversion. (For interpretation of the references to color in this figure legend, the reader is
referred to the web version of this article.)

is gradually increased by unity steps. In all cases, after an initial
decrease the Sigm-unreg test error increases significantly.
On the contrary, the OCReP test error curves keep decreasing,
albeit at slower and slower rate, thus showing also a good
capability of overfitting control of the method.
We aim now at comparing the results obtained when the tradeoff value of γ is searched by cross-validation, with the two different
frameworks discussed so far, i.e. OCReP and Sigm-unreg.
A 70%/30% split between training and test set is applied; we
then perform a three-fold cross-validation for the selection of the
¯ at which the minimum error is
number of hidden neurons M

recorded in all cases. Test errors are again evaluated as the average
of 50 different random choices of input weights.
The numerical results of the simulation are presented in
Tables 5 and 6, respectively for regression and classification tasks,
¯
with their standard deviations (Std) and M.
Best test errors are evidenced in bold, whenever the difference
between OCReP and cross-validation is statistically significant.
We see that our proposed regularization technique provides,
for regression datasets, performance comparable with the crossvalidation option but always a better performance (with statistical
significance at 99% level) with respect to the unregularized case.

84

R. Cancelliere et al. / Neural Networks 71 (2015) 76–87

Fig. 6. Test error trends for classification datasets: OCReP vs. unregularized pseudoinversion. (For interpretation of the references to color in this figure legend, the reader
is referred to the web version of this article.)
Table 5
Hidden layer optimization for regression tasks. For Delta Ailerons, average errors
and standard deviations have to be multiplied by 10−4 .
Abalone

Housing

Delta Ailerons

Machine Cpu

2.12
0.32
178

4.25
0.13
255

1.58
0.0048
298

31.22
0.78
63

4.19
0.25
250

1.58
0.0036
93

31.51
1.25
70

4.73
0.20
76

1.62
0.57
74

34.44
2.89
15

OCReP
Err.
Std.
¯
M

Cross-validation
Err.
Std.
¯
M

2.11
0.0097
110

Sigm-unreg
Err.
Std.
¯
M

2.14
0.014
31

For classification datasets in three cases out of four OCReP
provides a better performance with respect to cross-validation, and
always a better performance with respect to the Sigm-unreg case.
In all such cases, the statistical significance is at the 99% level.
Also, in almost all cases smaller standard deviations are
associated with the OCReP method, suggesting a lower sensitivity
to initial input weights conditions.
5.3. Additional considerations
The proposed method OCReP presents in our opinion two
features of interest: on one side, its computational efficiency, and
on the other side its optimal conditioning.

Table 6
Hidden layer optimization for classification tasks.
Iris

Wine

Diabetes

Segment

1.6
1.10
67

1.73
1.25
91

25.53
0.51
291

2.50
0.32
760

2.12
1.26
14

2.10
2.27
137

25.2
1.29
25

2.65
0.38
620

2.31
1.48
67

3.20
2.09
91

25.92
1.12
291

4.45
0.47
760

OCReP
Err.
Std.
¯
M

Cross-validation
Err.
Std.
¯
M
Sigm-unreg
Err.
Std.
¯
M

Our goal of optimal analytic determination of the regularization
parameter γ results in a dramatic improvement in the computing
requirements with respect to experimental tuning by search over a
pre-defined large grid of Nγ tentative values. In the latter case, for
each choice of γ over the selected range, at least a pseudoinversion
is required for every output weight determination, thus increasing
the computational load by a factor Nγ .
Besides, our method is designed explicitly for optimal conditioning. In our simulations, we verify that the goal is fulfilled by
evaluating average condition numbers of hidden layer output matrices. The statistics is performed over 50 different configurations
of input weights and a fixed number of hidden units, namely the
largest used in Section 5.1 for each dataset. The results are summarized in Tables 7 and 8, respectively for regression and classification datasets. On the first row of each table, we list the ratio

R. Cancelliere et al. / Neural Networks 71 (2015) 76–87
Table 7
Condition number comparison for regression datasets.

µ(H reg )/µ(H + )
µ(H reg )/µ(H CV )

Abalone

Housing

Delta Ailerons

Machine Cpu

0.0002
0.8

0.0008
0.3

0.00007
0.3

0.0001
0.1

Table 12
Kibria estimate of ridge parameter: results at fixed number of hidden neurons for
regression datasets. For Delta Ailerons, average errors and standard deviations have
to be multiplied by 10−4 .

Err.
Std
Err.
Std
Err.
Std
Err.
Std

50
Table 8
Condition number comparison for classification datasets.

µ(H reg )/µ(H + )
µ(H reg )/µ(H CV )

100
M

Iris

Wine

Diabetes

Segment

200

0.00002
0.2

0.005
0.4

0.0007
0.1

0.000005
0.2

300

Table 9
GCV results at fixed number of hidden neurons for small datasets.

Err.
Std
Err.
Std

50
M
100

Iris

Wine

Machine Cpu

2.47
1.06
3.06
1.08

3.66
2.42
3.77
2.44

33.03
1.27
36.06
1.13

Table 10
GCV results at fixed number of hidden neurons for large
size datasets.
Segment
1000

Err.
Std

11.39
0.75

1500

Err.
Std

14.72
0.803

M

Table 11
GCV results at fixed number of hidden neurons for medium size datasets. For Delta
Ailerons, average errors and standard deviations have to be multiplied by 10−4 .

50
100
M
200
300

Err.
Std
Err.
Std
Err.
Std
Err.
Std

Abalone

Housing

Delta Ailerons

Diabetes

2.13
0.017
2.15
0.021
2.32
0.10
2.98
0.42

4.89
0.45
5.05
0.70
6.78
2.35
8.07
2.89

1.60
0.0103
1.63
0.0297
1.74
0.0892
2.20
0.4054

25.2
1.22
26.66
1.39
27.73
1.27
27.14
1.15

of average condition numbers of matrices H reg , and H + , associated
respectively to OCReP and Sigm-unreg, i.e. regularized and unregularized approaches. On the second row, we list the ratio of average
condition numbers of matrices H reg and H CV , thus comparing our
regularization approach with the more conventional one, the latter
using cross-validation.
Not surprisingly, our regularization method provides a significant improvement on conditioning with respect to the unregularized approach, as evidenced by ratio values much smaller than
unity. Besides, OCReP also provides better conditioned matrices
than those derived by selection of γ through cross-validation, since
the corresponding condition numbers are systematically smaller in
the former case, sometimes up to an order of magnitude.
6. Comparison with other approaches
Since the literature provides a host of different recipes for
either the choice of the regularization parameter, or the actual
regularization algorithm, hereafter we focus on a couple of specific
frameworks.
6.1. Other choices of regularization parameter
Among the approaches mentioned in Section 2, we primary
select the technique of generalized cross-validation (GCV) from

85

Abalone

Housing

Delta Ailerons

Machine Cpu

2.32
0.37
2.38
0.90
2.20
0.13
2.34
1.01

5.72
0.84
5.45
0.86
5.31
0.76
5.46
1.60

1.63
0.027
1.64
0.08
1.65
0.15
1.62
0.035

34.28
4.67
32.40
3.72

Golub et al. (1979), described by Eqs. (7) and (8), for comparison
with our method. The main motivation for our choice is its
independence on the estimate of the error variance σ 2 , which is
a characteristic shared with our case. For each dataset, we select
the same fixed numbers of hidden units as in Section 5.1: then
for each case Eq. (7) is minimized over the set of 50 values of
γ [10−25 , 10−24 · · · 1025 ] and for 50 different configurations of
input weights.
We evaluate the mean and standard deviation of the corresponding regularized test error, reported in Tables 9–11. We also
remind that the tabulated error ‘‘Err’’ is either the average RMSE
for regression tasks, or the average misclassification rate for classification tasks; ‘‘Std’’ is the corresponding standard deviation. The
performance comparison is based on statistical significance at 99%
level.
Whenever GCV provides test error values statistically better
than OCReP (listed in Tables 2–4), they are marked in bold.
We remark that in all cases listed in Tables 2 and 3 OCReP
provides statistically better results than GCV. The situation of
medium size datasets evidences a somewhat mixed behavior: with
50 hidden neurons, GCV wins; with 100 neurons, for three out of
four datasets (i.e. Abalone, Housing and Diabetes) the performance
is statistically comparable. In all other cases of Table 4 OCReP again
provides better statistical results than GCV.
We make two other comparisons, using the ridge estimates
described in Eq. (13) and Eq. (9) of Dorugade and Kashid (2010),
and proposed respectively by Hoerl and Kennard (1970) and Kibria
(2003):

γK =

p
1  σˆ 2

p

γHK =

1

αˆ i2

σˆ 2
.
2
αˆ max

,

(30)

(31)

Our experimentation is made only for regression datasets
because the theoretical background of Dorugade and Kashid
(2010), and of most of other works referred in Section 2, directly
applies to the case in which the quantity Y in Eq. (1) is a one column
matrix. In our formulation Y is the desired target T and it is a onecolumn matrix only for regression tasks.
For each dataset we applied both methods described by Eqs.
(30) and (31); we select the same fixed numbers of hidden units
as in Section 5.1 and perform 50 experiments with different
configuration of input weights.
Each step of pseudoinversion is regularized for each method
with the corresponding γ value. We evaluate the mean and standard deviation of the regularized test errors, reported respectively
in Tables 12 and 13.
Whenever the methods provide test error values statistically
better than OCReP (listed in Tables 2 and 4), they are marked in
bold.

86

R. Cancelliere et al. / Neural Networks 71 (2015) 76–87

Table 13
H–K estimate of ridge parameter: results at fixed number of hidden neurons for
regression datasets. For Delta Ailerons, average errors and standard deviations have
to be multiplied by 10−4 .

50
100
M
200
300

Abalone

Housing

Delta Ailerons

Machine Cpu

Err.
Std
Err.
Std
Err.
Std

2.13
0.016
2.14
0.90
2.33
0.10

4.87
0.44
4.98
0.67
8.101
2.83

1.60
0.01
1.62
0.029
1.73
0.08

34.28
2.37
37.39
3.18

Err.
Std

2.95
0.41

29.06
9.26

2.21
0.41

Table 14
Comparison between OCReP and ELM.

Err.
Std.
Err.
Std

OCReP
ELM

Iris

Wine

Diabetes

Segment

2.22
0.21
2.4
2.29

1.28
0.88
1.53
1.81

21.06
0.65
22.05
2.18

3.40
0.25
3.93
0.69

Table 15
Comparison between OCReP and RELM.
Diabetes

Segment

OCReP

Err.
Std.
¯
M

25.53
0.51
291

2.50
0.32
760

RELM

Err.
Std.
¯
M

21.81
2.55
15

4.49
0.0074
200

We remark that the method by Kibria obtains a better performance in two cases over sixteen, while OCReP in 12 cases over sixteen. Besides, the method by Hoerl and Kennard obtains a better
performance in three cases over sixteen, while OCReP in eight cases
over sixteen. For both methods, better performance is achieved
only for the case of M = 50 neurons.
It may be noted that with respect to processing requirements
OCReP has clear advantages, since it requires only a SVD step for
each determination of γ , while the above two methods require full
spectral decomposition and an additional matrix inversion.

Table 16
Comparison between OCReP and TROP-ELM. For Delta Ailerons, average errors and
standard deviations have to be multiplied by 10−4 .
Abalone

Delta
Ailerons

Machine
Cpu

Housing

OCReP

Err.
Std.
¯
M

2.12
0.32
178

1.58
0.0048
298

31.22
0.78
63

4.25
0.13
255

TROPELM

Err.
¯
M

2.19
42

1.64
80

264.03
28

34.35
59

Heeswijk, Bas, Simula, and Lendasse (2011), we note that OCReP
achieves always lower RMSE values3 (with statistical significance),
as can be seen from Table 16.
Besides, in our opinion our method is simpler, in the sense that
it uses a single step of regularization rather than two.
In Martinez-Martinez et al. (2011), an algorithm is proposed for
pruning ELM networks by using regularized regression methods:
the crucial step of regularization parameter determination is
solved by creating K different models, each one based on a different
value of this parameter, among which the best one is selected using
a Bayesian information criterion. Authors state that a typical value
for K is 100, thus an heavy computational load is required, and the
method is focused on regression tasks.
7. Conclusions
In the context of regularization techniques for single hidden
layer neural networks trained by pseudoinversion, we provide an
optimal value of the regularization parameter γ by analytic derivation. This is achieved by defining a convenient regularized matricial
formulation in the framework of Singular Value Decomposition, in
which the regularization parameter is derived under the constraint
of condition number minimization. The OCReP method has been
tested on UCI datasets for both regression and classification tasks.
For all cases, regularization implemented using the analytically derived γ is proven to be very effective in terms of predictivity, as evidenced by comparison with implementations of other approaches
from the literature, including cross-validation. OCReP avoids hundreds of pseudoinversions usually needed by most other methods,
i.e. it is quite computationally attractive.
Acknowledgments

6.2. Alternative regularization methods
A first comparison can be done with the work by Huang, Zhu,
and Siew (2012), whose technique Extreme Learning Machine
(ELM) uses a cost parameter C that can be considered as related
to the inverse of our regularization parameter γ . As authors state,
in order to achieve good generalization performance, C needs to be
chosen appropriately. They do this by trying 50 different values of
this parameter: [2−24 , 2−23 , . . . , 224 , 225 ].
A fair comparison can be done on our classification datasets,
using their number of hidden neurons, i.e. 1000. Our optimal choice
of γ allows to obtain a better performance on all datasets (with
statistical significance assessed at the same confidence level than
previous experiments) (see Table 14).
Deng, Zheng, and Chen (2009) propose a Regularized Extreme
Learning Machine (hereafter, RELM) in which the regularization
parameter is selected according to a similar criterion among 100
values: [2−50 , 2−49 , . . . , 250 ]. Because their performance is optimized with respect to the number of hidden neurons, for the sake
of comparison we use OCReP values from Table 6. We obtain a statistically significant better performance on dataset Segment, while
for Diabetes the method RELM performs better (see Table 15).
Comparing our results on the common regression datasets
with the alternative method TROP-ELM proposed by Miche, van

This work benefits from the thorough revision by our anonymous referees, and from fruitful exchanges with several colleagues.
The activity has been partially carried on in the context of the Visiting Professor Program of the Gruppo Nazionale per il Calcolo Scientifico (GNCS) of the Italian Istituto Nazionale di Alta Matematica
(INdAM). This work has been partially supported by ASI contracts
(Gaia Mission—The Italian Participation to DPAC) I/058/10/0-1 and
2014-025-R.0.
Appendix A. Supplementary data
Supplementary material related to this article can be found
online at http://dx.doi.org/10.1016/j.neunet.2015.07.015.
References
Ajorloo, H., Manzuri-Shalmani, M. T., & Lakdashti, A. (2007). Restoration of damaged
slices in images using matrix pseudo inversion. In Proceedings of the 22nd
international symposium on computer and information sciences (pp. 1–6).
Bache, K., & Lichman, M. (2013). UCI machine learning repository.

3 In that work, performance and related statistics are expressed in terms of MSE;
we only derived the corresponding RMSE for comparison with our results.

R. Cancelliere et al. / Neural Networks 71 (2015) 76–87
Badeva, V., & Morozov, V. (1991). Problèmes incorrectement posés: Théorie et
applications en identification, filtrage optimal, contrôle optimal, analyse et
synthèse de systèmes, reconnaissance d’images. Série Automatique. Masson.
Berger, J. (1976). Minimax estimation of a multivariate normal mean under
arbitrary quadratic loss. Journal of Multivariate Analysis, 6, 256–264.
Bishop, C. M. (2006). Pattern recognition and machine learning. In Information
science and statistics, Secaucus, NJ, USA: Springer-Verlag New York, Inc.
Bousquet, O., & Elisseeff, A. (2002). Stability and generalization. Journal of Machine
Learning Research, 2, 499–526.
Cancelliere, R. (2001). A high parallel procedure to initialize the output weights of a
radial basis function or bp neural network. In Proceedings of the 5th international
workshop on applied parallel computing, new paradigms for HPC in industry and
academia, PARA’00. (pp. 384–390). London, UK, UK: Springer-Verlag.
Cancelliere, R., Gai, M., Artières, T., & Gallinari, P. (2012). Matrix pseudoinversion for
image neural processing. Lecture Notes in Computer Science, 7667(V), 116–125.
Deng, W., Zheng, Q., & Chen, L. (2009). Regularised extreme learning machine. In
Proceedings of the IEEE symposium on computational intelligence and data mining.
Devroye, L. P., & Wagner, T. (1979). Distribution-free performance bounds
for potential function rules. IEEE Transactions on Information Theory, 25(5),
601–604.
Dorugade, A., & Kashid, D. (2010). Alternative method for choosing ridge parameter
for regression. Applied Mathematical Sciences, 4, 447–456.
Fu, W. (1998). Penalized regressions: the bridge vs. the lasso. Journal of
Computational and Graphical Statistics, 7, 397–416.
Fuhry, M., & Reichel, L. (2012). A new Tikhonov regularization method. Numerical
Algorithms, 59(3), 433–445.
Gallinari, P., & Cibas, T. (1999). Practical complexity control in multilayer
perceptrons. Signal Processing, 74, 29–46.
Geman, S., Bienenstock, E., & Doursat, R. (1992). Neural networks and the
bias/variance dilemma. Neural Computation, 4, 1–58.
Girosi, F., Jones, M., & Poggio, T. (1995). Regularization theory and neural networks
architectures. Neural Computation, 7, 219–269.
Golub, G. H., Hansen, P. C., & O’Leary, D. P. (1999). Tikhonov regularization and total
least squares. SIAM Journal of Mathematical Analysis, 21(1), 185–194.
Golub, G., Heath, M., & Wahba, G. (1979). Generalized cross-validation as a method
for choosing a good ridge parameter. Technometrics, 21, 215–223.
Golub, G. H., & Van Loan, C. F. (1996). Matrix computations (3rd ed.). Baltimore, MD,
USA: Johns Hopkins University Press.
Hastie, T., Tibshirani, R., & Friedman, J. (2009). The elements of statistical learning:
data mining, inference, and prediction (2nd ed.). Springer.
Haykin, S. (1999). Neural networks: a comprehensive foundation. In International
edition, Prentice Hall.
Helmy, T., & Rasheed, Z. (2009). Multi-category bioinformatics dataset classification
using extreme learning machine. In Proceedings of the eleventh conference on
congress on evolutionary computation, CEC’09. (pp. 3234–3240). Piscataway, NJ,
USA: IEEE Press.
Hoerl, A. (1962). Application of ridge analysis to regression problems. Chemical
Engineering Progress, 58, 54–59.
Hoerl, A., & Kennard, R. (1970). Ridge regression: Biased estimation for
nonorthogonal problems. Technometrics, 12, 55–67.
Hoerl, A., & Kennard, R. (1976). Ridge regression: iterative estimation of the biasing
parameter. Communications in Statistics, A5, 77–88.
Huang, G.-B., Zhu, Q.-Y., & Siew, C.-K. (2006). Extreme learning machine: theory and
applications. Neurocomputing, 70(1), 489–501.
Huang, G.-B., Zhu, Q.-Y., & Siew, C.-K. (2012). Extreme learning machine for
regression and multiclass classification. IEEE Transactions on Systems, Man and
Cybernetics—Part B: (Cybernetics), 42(2), 513–529.
Kearns, M., & Ron, D. (1999). Algorithmic stability and sanity-check bounds for
leave-one-out cross-validation. Neural Computation, 11(6), 1427–1453.
Khalaf, G., & Shukur, G. (2005). Choosing ridge parameter for regression problem.
Communications in Statistics—Theory and Methods, 34, 1177–1182.
Kibria, B. (2003). Performance of some new ridge regression estimators.
Communications in Statistics—Simulation and Computation, 32, 419–435.

87

Kohno, K., Kawamoto, M., & Inouye, Y. (2010). A matrix pseudoinversion lemma and
its application to block-based adaptive blind deconvolution for MIMO systems.
Transactions on Circuits and Systems Part I, 57(7), 1449–1462.
Lawless, J., & Wang, P. (1976). A simulation study of ridge and other regression
estimators. Communications in Statistics, A5, 307–324.
Lowe, D. (1989). Adaptive radial basis function nonlinearities, and the problem of
generalisation. In First IEE international conference on artificial neural networks
(Conf. Publ. No. 313) (pp. 171–175).
Mardikyan, S., & Cetin, E. (2008). Efficient choice of biasing constant for ridge
regression. International Journal of Contemporary Mathematical Sciences, 3,
527–547.
Martinez-Martinez, J., Escandell-Montero, P., Soria-Olivas, E., Martín-Guerrero, J.,
Magdalena-Benedito, R., & Juan, G.-S. (2011). Regularized extreme learning
machine for regression problems. Neurocomputing, 74, 3716–3721.
McDonald, G., & Galarneau, D. (1975). A Monte Carlo evaluation of some ridge-type
estimators. Journal of the American Statistical Association, 70, 407–416.
Miche, Y., van Heeswijk, M., Bas, P., Simula, O., & Lendasse, A. (2011). TropELM: A double-regularized ELM using lars and Tikhonov regularization.
Neurocomputing, 74(16), 2413–2421.
Mukherjee, S., Niyogi, P., Poggio, T., & Rifkin, R. (2003). Statistical learning: stability
is sufficient for generalization and necessary and sufficient for consistency
of empirical risk minimization. CBCL, Paper 223, Massachusetts Institute of
Technology.
Mukherjee, S., Niyogi, P., Poggio, T., & Rifkin, R. (2006). Learning theory: stability
is sufficient for generalization and necessary and sufficient for consistency of
empirical risk minimization. Advances in Computational Mathematics, 25(1–3),
161–193.
Nguyen, T. D., Pham, H. T. B., & Dang, V. H. (2010). An efficient pseudo inverse
matrix-based solution for secure auditing. In Proceedings of the IEEE international
conference on computing and communication technologies, research, innovation,
and vision for the future, IEEE international conference.
Nordberg, L. (1982). A procedure for determination of a good ridge parameter in
linear regression. Communications in Statistics, A11, 285–309.
Pao, Y. H., Park, G. H., & Sobajic, D. J. (1994). Learning and generalization
characteristics of random vector functional-link net. Neurocomputing, 6,
163–180.
Penrose, R., & Todd, J. A. (1956). On best approximate solutions of linear matrix
equations. Mathematical Proceedings of the Cambridge Philosophical Society, null,
17–19.
Poggio, T., & Girosi, F. (1990a). Networks for approximation and learning.
Proceedings of the IEEE, 78(9), 1481–1497.
Poggio, T., & Girosi, F. (1990b). Regularization algorithms for learning that are
equivalent to multilayer networks. Science, 247(4945), 978–982.
Poggio, T., Rifkin, R., Mukherjee, S., & Niyogi, P. (2004). General conditions for
predictivity in learning theory. Letters to Nature, 428, 419–422.
Rao, C., & Mitra, S. (1971). Wiley series in probability and mathematical statistics:
applied probability and statistics, Generalized inverse of matrices and its
applications. Wiley.
Saleh, A., & Kibria, B. (1993). Performances of some new preliminary test ridge
regression estimators and their properties. Communications in Statistics—Theory
and Methods, 22, 2747–2764.
Tibshirani, R. (1996). Regression shrinkage and selection via the lasso. Journal of the
Royal Statistical Society, 58, 267–288.
Tikhonov, A. N. (1963). Solution of incorrectly formulated problems and the
regularization method. Soviet Mathematics Doklady, 4, 1035–1038.
Tikhonov, A., & Arsenin, V. (1977). Scripta series in mathematics, Solutions of ill-posed
problems. Washington DC: Winston.
Wang, X. (2013). Special issue on extreme learning machines with uncertainty.
International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems, 21.
Wang, X.-Z., Wang, D.-H, & Huang, G.-B. (2012). Special issue on extreme learning
machines. Soft Computing, 16(9), 1461–1463.
Yu, D., & Deng, L. (2012). Efficient and effective algorithms for training singlehidden-layer neural networks. Pattern Recognition Letters, 33(5), 554–558.

